{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Раздел 7. Машинное обучение"
   ],
   "metadata": {
    "id": "Lv-xkzaEAwO6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Тема 7.1 Задачи, решаемые методами машинного обучения, многомерные базы данных NoSQL"
   ],
   "metadata": {
    "id": "menqQhyhAXNH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Лекция \n",
    "\n",
    "Вопросы: \n",
    "1. Задачи, решаемые методами машинного обучения. \n",
    "2. Особенности работы слабоструктурированных СУБД.\n",
    "\n",
    "**Машинное обучение: понятийный аппарат**\n",
    "\n",
    "Машинное обучение представляет собой науку (и искусство) программирования\n",
    "компьютеров для того, чтобы они могли обучаться на основе данных.\n",
    "\n",
    "Говорят, что компьютерная программа обучается на основе опыта *Е* по отношению\n",
    "к некоторой задаче *Т* и некоторой оценке производительности *Р*,\n",
    "если ее производительность на *Т*, измеренная посредством *Р*, улучшается\n",
    "с опытом *Е*.\n",
    "\n",
    "Три компонента машинного обучения:\n",
    "- данные –-- собираются всевозможными способами. Чем больше данных, тем эффективней машинное обучение и точнее будущий результат;\n",
    "- признаки –-- определяют, на каких параметрах строится машинное обучение;\n",
    "- алгоритм –-- выбор метода машинного обучения (при условии наличия хороших данных) будет влиять на точность, скорость работы и размер готовой модели.\n",
    "\n",
    "** Задача обучения**\n",
    "\n",
    "Пусть \n",
    "- $X$ -- множество объектов, причем любой объект $X_i \\in X$ описывается единым набором $m$ признаков \n",
    "$$\n",
    "x_i = (x_{i1}, x_{i2}, \\ldots, x_{im} )\n",
    "$$ \n",
    "- $Y$ -- множество меток классов;\n",
    "- $y : X \\to Y$ -- неизвестная зависимость;\n",
    "- $X_1, X_2, \\ldots, X_n \\in X$ -- некоторые известные объекты, составляющие обучающее множество;\n",
    "- $Y_1, Y_2, \\ldots, Y_n \\in Y$ --- известные метки классов для объектов $X_1, X_2, \\ldots, X_n \\in X$; \n",
    "\n",
    "Найти $y : X \\to Y$ -- алгоритм, правило, решающую функцию для всех объектов из множества $X$.\n",
    "\n",
    "**Типы задач**\n",
    "\n",
    "Классификация:\n",
    "- $Y=\\{−1,+1\\}$ — классификация на 2 класса;\n",
    "- $Y=\\{1,...,M\\}$ — на $M$ непересекающихся классов;\n",
    "- цель: научиться определять, к какому классу принадлежит объект;\n",
    "- примеры: распознавание текста по рукописному вводу; определение того, находится на фотографии человек или кот; определение, является ли письмо спамом;\n",
    "- методы: метод ближайших соседей, дерево решений, логистическая регрессия, метод опорных векторов, байесовский классификатор, cверточные нейронные сети.\n",
    "\n",
    "Восстановление регрессии:\n",
    "- $Y=\\mathbb{R}$;\n",
    "- цель: получать прогноз на основе выборки объектов;\n",
    "- примеры: предсказание стоимости акции через полгода; предсказание прибыли магазина в следующем месяце;\n",
    "- методы: линейная регрессия, дерево решений, метод опорных векторов.\n",
    "\n",
    "Кластеризация:\n",
    "- цель: разбить множество объектов на подмножества (кластеры) таким образом, чтобы объекты из одного кластера были более похожи друг на друга, чем на объекты из других кластеров по какому-либо критерию;\n",
    "- примеры: сегментация клиентов;  подбор рекомендаций для пользователя; определение аномалий;\n",
    "- методы: иерархическая кластеризация, эволюционные алгоритмы кластеризации, EM-алгоритм.\n",
    "\n",
    "Уменьшение размерности:\n",
    "- цель: научиться описывать данные не $N$ признаками, а меньшим числом для повышения точности модели или последующей визуализации;\n",
    "- примеры: визуализация в двумерном или трехмерном пространстве; сжатие данных;\n",
    "- методы: метод главных компонент, метод факторного анализа.\n",
    "\n",
    "Выявление аномалий:\n",
    "- цель: научиться выявлять аномалии в данных. Отличительная особенность задачи от классификации — примеров аномалий для тренировки модели очень мало, либо нет совсем; поэтому для ее решения необходимы специальные методы;\n",
    "- примеры: определение мошеннических транзакций по банковской карте; обнаружение событий, предвещающих землетрясение;\n",
    "- методы: экстремальный анализ данных, аппроксимирующий метод, проецирующие методы.\n",
    "\n",
    "Типы задач машинного обучения принято разделять на три категории:\n",
    "- обучение с учителем (supervised learning):\n",
    "данные, подготовленные для анализа, изначально содержат правильный ответ, поэтому цель алгоритма –выявить взаимосвязи между данными и правильным ответом, оптимальные в некотором смысле (критерий);  \n",
    "- обучение без учителя (unsupervised learning):\n",
    "алгоритм, обрабатывая массивы данных, должен самостоятельно выявлять закономерности, структуры;\n",
    "- обучение с подкреплением (reinforcement learning):\n",
    "алгоритм пытается найти оптимальные действия, которые будет предпринимать, находясь в наборе различных сценариев.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=166knuSlIW2hZsJQQiFo0fgwytI3MTxeX' width=\"600\" height=\"500\" />\n",
    "<figcaption>Классификация типов задач ML</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "**Этапы машинного обучения**\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=160ZRTT83CYvwjF09tok5lOcHeNf7J2qU' width=\"400\" height=\"500\" />\n",
    "<figcaption>Этапы машинного обучения</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "**Многомерные базы данных NoSQL**\n",
    "\n",
    "NoSQL (от англ. not only SQL — не только SQL) --- обозначение широкого класса разнородных систем управления базами данных, появившихся в конце 2000-х — начале 2010-х годов и существенно отличающихся от традиционных реляционных СУБД с доступом к данным средствами языка SQL. Применяется к системам, в которых делается попытка решить проблемы масштабируемости и доступности за счет полного или частичного отказа от требований атомарности и согласованности данных.\n",
    "\n",
    "ACID: базовые принципы реляционных баз данных\n",
    "\n",
    "- атомарность -- никакая транзакция не будет зафиксирована в системе частично. Будут либо выполнены все ее подоперации, либо не выполнено ни одной. Поскольку на практике невозможно одновременно и атомарно выполнить всю последовательность операций внутри транзакции, вводится понятие <<отката>>: если транзакцию не удается полностью завершить, результаты всех ее до сих пор произведенных действий будут отменены и система вернется во <<внешне исходное>> состояние --  со стороны будет казаться, что транзакции и не было;\n",
    "- согласованность -- транзакция, достигающая своего нормального завершения и тем самым фиксирующая свои результаты, сохраняет согласованность базы данных. Другими словами, каждая успешная транзакция по определению фиксирует только допустимые результаты;\n",
    "- изолированность -- во время выполнения транзакции параллельные транзакции не должны оказывать влияния на её результат;\n",
    "- устойчивость -- независимо от проблем на нижних уровнях (к примеру, обесточивание системы или сбои в оборудовании) изменения, сделанные успешно завершенной транзакцией, должны остаться сохранёнными после возвращения системы в работу.\n",
    "\n",
    "Принципы BASE баз данных NoSQL\n",
    "\n",
    "\n",
    "С середины 2000-х годов для построения распределенных СУБД предполагается отказ от части требований `ACID` (для обоснования чего используются теорема `CAP`, теорема `PACELC`) или снижение строгости требований (`BASE`).\n",
    "\n",
    "Во второй половине 2000-х годов сформулирован подход к построению распределенных систем, в которых требования целостности и доступности выполнены не в полной мере, названый акронимом BASE (от англ. Basically Available, Soft-state, Eventually consistent — базовая доступность, неустойчивое состояние, согласованность в конечном счете), при этом такой подход напрямую противопоставляется ACID. Под базовой доступностью подразумевается такой подход к проектированию приложения, чтобы сбой в некоторых узлах приводил к отказу в обслуживании только для незначительной части сессий при сохранении доступности в большинстве случаев. Неустойчивое состояние подразумевает возможность жертвовать долговременным хранением состояния сессий (таких как промежуточные результаты выборок, информация о навигации, контексте), при этом концентрируясь на фиксации обновлений только критичных операций. Согласованности в конечном счете, трактующейся как возможность противоречивости данных в некоторых случаях, но при обеспечении согласования в практически обозримое время.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=169L9e8Y1KXjF5vhbF_J55Nw6X8i5ks2V' width=\"600\" height=\"500\" />\n",
    "<figcaption>Базы данных NoSQL</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "EfHJPgWgBTm5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Тема 7.2 Деревья решений: лекция\n",
    "\n",
    "Задача классификации\n",
    "\n",
    "Содержательная постановка задачи классификации \n",
    "\n",
    "Пусть имеется множество объектов и ассоциированное с ним конечное\n",
    "множество классов. Пусть также для некоторого конечного подмножества множества объектов, называемого выборкой или обучающим множеством, известно к каким классам принадлежат его элементы. Тогда под задачей классификации будем понимать задачу построения по обучающему множеству такого **решающего правила**, которое будет относить произвольный объект к одному и только одному из заданных классов.\n",
    "\n",
    "Формальная постановка задачи классификации \n",
    "\n",
    "Пусть $X=\\{x_1,x_2,\\ldots \\}$ --- множество исследуемых объектов,\n",
    "каждый из которых характеризуется набором признаков $Z_1, Z_2,\n",
    "\\ldots, Z_p$. Для каждого признака $Z_r$ известно множество\n",
    "значений $Z_r=\\{z_{r1}, z_{r2}, \\ldots, z_{rm}\\}$,\n",
    "$r=\\overline{1,p}$. Тогда каждый объект $x_l$, $l=1,2,\\ldots$,\n",
    "можно представить как множество значений признаков, т.е.\n",
    "$x_l=\\{z_{rh}\\}$, где $z_{rh} \\in Z_r$, $r=\\overline{1,p}$,\n",
    "$h=\\overline{1,m}$. Пусть также $Y=\\{y_1,y_2,\\ldots, y_k\\}$ ---\n",
    "заданное множество классов. Обозначим через $S=\\{(x_i,y_j)\\,|\\,\n",
    "x_i \\in X, y_j \\in Y, i=\\overline{1,n},j=\\overline{1,k}\\}$ ---\n",
    "обучающее множество, в котором каждому объекту $x_i \\in X$\n",
    "поставлен в соответствие класс $y_j \\in Y$. Требуется на основании\n",
    "обучающей выборки построить **решающее правило** для классификации\n",
    "произвольного объект из множества $X$.\n",
    "\n",
    "**Правило** называется **решающим**, если оно позволяет отделить объекты, принадлежащие одному классу, от остальных.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=16LC7XKiNLmQ1-jmNbNcM3KHmtz37YEY4' width=\"500\" height=\"450\" />\n",
    "<figcaption>Пример задачи классификации</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Деревья решений**\n",
    "\n",
    "Дерево решений --- метод представления **решающих правил** в виде древовидной иерархической структуры, включающей в себя элементы двух типов -- узлы (node) и листья (leaf).\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=16NhCkhCCqYbQ8UL-jThbEceboUu2iTdT' width=\"600\" height=\"450\" />\n",
    "<figcaption>Пример дерева решений</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "В узлах расположены решающие правила и подмножества наблюдений, которые им удовлетворяют. В листьях содержатся классифицированные деревом наблюдения: каждый лист ассоциируется с одним из классов, и объекту, который распределяется в лист, присваивается соответствующая метка класса.\n",
    "\n",
    "Если класс, присвоенный деревом, совпадает с целевым классом, то объект является распознанным, в противном случае -- нераспознанным. Самый верхний узел дерева называется корневым. \n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=16RL6_EUqr5XyKo-_Y8z5BUNtXbKyxW6a' width=\"450\" height=\"200\" />\n",
    "<figcaption>Корневой узел дерева решений</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "Теоретически, алгоритм может генерировать новые разбиения до тех пор, пока все примеры не будут распознаны правильно, т.е. пока подмножества, ассоциированные с листьями, не станут однородными по классовому составу. Однако это приводит к усложнению дерева: большое число ветвлений, узлов и листьев усложняет его структуру и ухудшает его интерпретируемость. Поэтому на практике размер дерева ограничивают даже за счет некоторой потери точности. Данный процесс называется упрощением деревьев решений и может быть реализован с помощью методов ранней остановки и отсечения ветвей.\n",
    "\n",
    "Процесс построения дерева решений состоит в последовательном рекурсивном разбиении обучающего множество на подмножества с применением решающих правил в узлах. Этот процесс продолжают до того, пока все узлы в конце ветвей не станут листами.\n",
    "\n",
    "Узел становится листом в двух случаях:\n",
    "- естественным образом -- когда он содержит единственный объект или объект только одного класса;\n",
    "- после достижения заданного условия остановки алгоритм -- например, минимально допустимое число примеров в узле или максимальная глубина дерева.\n",
    "\n",
    "Построение осуществляется в 4 этапа:\n",
    "- выбрать атрибут для осуществления разбиения в данном узле;\n",
    "- определить критерий остановки обучения;\n",
    "- выбрать метод отсечения ветвей;\n",
    "- оценить точность построенного дерева.\n",
    "\n",
    "Выбор атрибута разбиения\n",
    "\n",
    "Разбиение должно осуществляться по определенному правилу, для которого и выбирают атрибут. Причем выбранный атрибут должен разбить множество наблюдений в узле так, чтобы результирующие подмножества содержали примеры с одинаковыми метками класса или были максимально приближены к этому.\n",
    "\n",
    "Выделяют следующие критерии для выбора признака разбиения:\n",
    "- информационный выигрыш -- энтропийный коэффициент;\n",
    "- примесь (критерий) Джини;\n",
    "- понижение дисперсии.\n",
    "\n",
    "Информационный выигрыш, который основывается на понятии энтропии и объема информации из теории информации.\n",
    "\n",
    "Пусть имеется множество сообщений $M=\\{m_1, m_2, \\ldots, m_n\\}$ и\n",
    "соответствующее ему множество $P=\\{p(m_1), p(m_2), \\ldots,\n",
    "p(m_n)\\}$ --- значений вероятностей возникновения их сообщений.\n",
    "Тогда в качестве оценки информативности этих сообщений можно\n",
    "воспользоваться мерой энтропии множества $P$, рассчитываемой по\n",
    "формуле\n",
    "$$\n",
    "I(P)=\\sum\\limits_{i=1}^{n}-p(m_i)\\log_2p(m_i)=E\\left(-\\log_2p(m_i)\\right).\n",
    "$$\n",
    "Количество информации в сообщении измеряется в битах.\n",
    "\n",
    "Пусть $S$ --- исходное обучающее множество примеров. Выбрав в\n",
    "качестве узла дерева некоторый признак $Z_r$, принимающий~$m$\n",
    "значений, получим разбиение множества $S$ на $m$ попарно\n",
    "непересекающихся подмножеств $S_1$, $S_2$,$\\ldots$, $S_m$. Тогда\n",
    "информация, необходимая для завершения построения дерева решений,\n",
    "составляет\n",
    "$$\n",
    "E(Z_r)=\\sum\\limits_{i=1}^{m}\\dfrac{|S_i|}{|S|}I(S_i),\n",
    "$$\n",
    "где $|S_i|$, $|S|$ --- мощности отдельного подмножества и\n",
    "обучающего множества в целом; $I(S_i)$ --- информативность\n",
    "отдельного подмножества согласно формуле энтропии.\n",
    "\n",
    "Количество информации, полученное при выборе признака $Z_r$,\n",
    "вычисляется как разность общей информативности дерева и объема\n",
    "информации, необходимого для завершения построения дерева\n",
    "$$\n",
    "Gain(Z_r,S)=I(S)-E(Z_r).\n",
    "$$\n",
    "Признак $Z_r$ с наибольшим значением $Gain(Z_r,S)$ считается\n",
    "наиболее информативным.\n",
    "\n",
    "\n",
    "Отсечение ветвей\n",
    "\n",
    "Без ограничения <<роста>> дерево решений станет слишком большим и сложным, что сделает невозможной дальнейшую интерпретацию. На практике часто пользуются следующим приемом -- построить все возможные деревья, а потом выбрать те, которые при разумной глубине обеспечивают приемлемый уровень ошибки распознавания. Основная задача в такой ситуации -- поиск наиболее выгодного баланса между сложностью и точностью дерева.\n",
    "\n",
    "Метод отсечения ветвей реализуется в 3 шага:\n",
    "- строительство полного дерева, в котором листья содержат примеры одного класса;\n",
    "- определение двух показателей: относительную точность модели (отношение числа правильно распознанных примеров к общему числу примеров) и абсолютную ошибку (число неправильно классифицированных примеров);\n",
    "- удаление листов и узлов, потеря которых минимально скажется на точности модели и увеличении ошибки.\n",
    "\n",
    "Отсечение ветвей проводят противоположно росту дерева, то есть снизу вверх, путем последовательного преобразования узлов в листья.\n",
    "\n",
    "Критерии останова процесса построения дерева\n",
    "- Ограничение максимальной глубины дерева (max_depth)\n",
    "- Ограничение минимального числа объектов в листе (min_samples_leaf)\n",
    "- Ограничение максимального количества листьев в дереве.\n",
    "- Останов в случае, если все объекты в листе относятся к одному классу.\n",
    "- Требование, что функционал качества при дроблении улучшался как минимум на s\n",
    "процентов.\n",
    "\n",
    "Преимущества деревьев решений:\n",
    "- четкие правила классификации;\n",
    "- хорошо интерпретируются;\n",
    "- быстро обучаются и выдают прогноз;\n",
    "- малое число параметров.\n",
    "\n",
    "Недостатки деревьев решений:\n",
    "- очень чувствительнык шумам в данных, модель сильно меняется при небольшом\n",
    "изменении обучающей выборки;\n",
    "- разделяющая граница имеет свои ограничения;\n",
    "- необходимость борьбы с переобучением;\n",
    "- проблема поиска оптимального дерева NP-полная задача, поэтому на практике\n",
    "используется жадное построение дерева.\n",
    "\n",
    "\n",
    "**Случайные леса** \n",
    "\n",
    "[Случайный лес](https://www.mql5.com/ru/articles/3856) (random forest) --- это множество решающих деревьев. \n",
    "\n",
    "Случайный лес строится путем простого голосования деревьев решений по алгоритму Bagging (бэггинг). Bagging -- это искусственное слово, образованное от английского словосочетания bootstrap aggregating.\n",
    "\n",
    "Bootstrap в статистике -- это такой способ формирования выборки, когда выбирается ровно столько же объектов, сколько их исходно и было. Но объекты эти выбираются с повторениями. Иными словами, выбранный случайный объект возвращается обратно и может быть выбран повторно. При этом число объектов, которое будет выбрано, составит примерно 63% от исходной выборки, а оставшаяся доля объектов (примерно 37%) ни разу не попадет в обучающую выборку. По этой сформированной сэмплированной выборке обучаются базовые алгоритмы (в нашем случае деревья решений). Это тоже происходит случайным образом: берутся случайные подмножества (сэмплы) заданной длины и обучаются на выбранном случайном подмножестве признаков (атрибутов). Оставшиеся 37% выборки используются для проверки обобщающей способности построенной модели.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=16d99BidGYEcP-nixOHedTdxnFJyrl_Zn' width=\"800\" height=\"600\" />\n",
    "<figcaption>Алгоритм случайного леса</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "Затем все обученные деревья объединяются в композицию при помощи простого голосования, с использованием усредненной ошибки для всех сэмплов. В результате применения bootstrap aggregating уменьшается средний квадрат ошибки, снижается дисперсия обучаемого классификатора. На разных выборках ошибка будет отличаться не так сильно. \n",
    "\n",
    "Эффективность бэггинга заключается в том, что базовые алгоритмы (деревья решений) обучаются по различным случайным подвыборкам и их результаты могут сильно отличаться, но их ошибки взаимно компенсируются при голосовании.\n",
    "\n",
    "Можно сказать, что Random forest — это специальный случай бэггинга, когда в качестве базового семейства используются решающие деревья. При этом, в отличие от обычного способа построения решающих деревьев, не используется усечение дерева (pruning). Метод настроен на то, чтобы можно было построить композицию как можно быстрее по большим выборкам данных. Каждое дерево строится специфическим образом. Признак (атрибут) для построения узла дерева выбирается не из общего числа признаков, а из их случайного подмножества. В задаче классификации число признаков равно $\\sqrt{n}$. Все это является эмпирическими рекомендациями и называется декорреляцией: в разные деревья попадают разные наборы признаков, и деревья обучаются на разных выборках.\n",
    "\n",
    "**Оценки качества классификации**\n",
    "\n",
    "Матрица ошибок\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=16eVHRWPexiqIIitzCW6lX_Kbb40C5XpX' width=\"750\" height=\"100\" />\n",
    "<figcaption>Матрица ошибок</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Здесь $a(x)$ — это ответ алгоритма на объекте, а $y$ — истинная метка класса на этом объекте. Таким образом, ошибки классификации бывают двух видов: False Negative (FN) и False Positive (FP). P означает что классификатор определяет класс объекта как положительный (N — отрицательный). T значит что класс предсказан правильно (соответственно F — неправильно). Каждая строка в матрице ошибок представляет спрогнозированный класс, а каждый столбец — фактический класс.\n",
    "\n",
    "Метрики\n",
    "- `accuracy` (аккуратность) -- доля правильных ответов алгоритма\n",
    "$$\n",
    "accuracy = \\dfrac{TP+TN}{TP+TN+FP+FN}\n",
    "$$\n",
    "- `precision` (точность) -- доля правильных ответов модели в пределах класса\n",
    "$$\n",
    "precision = \\dfrac{TP}{TP+FP}\n",
    "$$\n",
    "- `recall` (полнота) -- это доля истинно положительных классификаций\n",
    "$$\n",
    "recall = \\dfrac{TP}{TP+FN}.\n",
    "$$"
   ],
   "metadata": {
    "id": "Fyvk5_V-A0hn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Тема 7.2 Деревья решений: практика\n",
    "\n",
    "Напомним содержательную постановку задачи классификации.  \n",
    "\n",
    "Пусть имеется множество объектов и ассоциированное с ним конечное\n",
    "множество классов. Пусть также для некоторого конечного подмножества множества объектов, называемого выборкой или **обучающим множеством**, известно к каким классам принадлежат его элементы. Тогда под задачей классификации будем понимать задачу построения по обучающему множеству такого **решающего правила**, которое будет относить произвольный объект к одному и только одному из заданных классов.\n",
    "\n",
    "Терминология:\n",
    "- Обучающая выборка (training sample) -- выборка, по которой производится настройка (оптимизация параметров) модели зависимости.\n",
    "- Тестовая (или контрольная) выборка (test sample) -- выборка, по которой оценивается качество построенной модели.\n",
    "- Проверочная выборка (validation sample) — выборка, по которой осуществляется выбор наилучшей модели из множества моделей, построенных по обучающей выборке.\n",
    "\n",
    "Вопрос выбора оптимального соотношения разделения на текущий момент является открытым. На практике исследователи прибегают к процентному разделению выборки, например в соотношении 50 %–25 %–25 %, или 50 %–30 %–20 %, или 33.(3) %33.(3) %–33.(3) %. \n",
    "Разделение всей совокупности данных необходимо для того, чтобы получить независимые выборки для разных этапов построения моделей.\n",
    "\n",
    "- Масштабирование -- процесс изменения диапазона признака. \n",
    "\n",
    "Масштабирование необходимо в том случае, если признаки измеряются в разных единицах, а значит покрывают разные диапазоны. Это сильно искажает результаты алгоритмов, учитывающих расстояние между измерениями.\n",
    "\n",
    "Распространенными способами масштабирования являются: \n",
    "- масштабирование по минимаксу:\n",
    "$$\n",
    "\\dfrac{x - x_{\\min}}{x_{\\max} - x_{\\min}}*N\n",
    "$$\n",
    "- стандартизация:\n",
    "$$\n",
    "\\dfrac{x - \\mu_x}{\\sigma_x}\n",
    "$$\n",
    "\n",
    "1. Dobbin K. K. Optimally splitting cases for training and testing high dimensional classifiers / K. K. Dobbin, R. M. Simon – BMC Med Genomics – 2011. – Vol. 4 (31). \n",
    "2. Afendras G. Optimality of training/test size and resampling effectiveness in cross-validation / G. Afendras, M. Markatou. – Journal of Statistical Planning and Inference. – 2019. – Vol. 199. – P. 286–301.\n",
    "\n",
    "Для решения задачи классификации используются инструменты библиотеки [scikit-learn](https://scikit-learn.org/stable/).\n",
    "\n",
    "В библиотеке `scikit-learn` деревья решений реализованы в классе \n",
    "`DecisionTreeClassifier`. Классификатор `DecisionTreeClassifier` принимает в качестве входных данных два массива: массив $X$, содержащий значения независимых признаков из обучающие выборки, и массив соответствующих значений целевой переменной $Y$ (метки классов для объектов из $X$).\n",
    "\n",
    "Применительно к процессу построения модели машинного обучения в библиотеке **scikit-learn** реализованы следующие группы методов:\n",
    "- оценщики (estimator): любой объект, который способен проводить оценку параметров на основе набора данных, называется **оценщиком**. Сама оценка производится методом `.fit()`, принимающего в качестве параметра набор аргументов (один или два в зависимости от задачи). Любой другой параметр(ы), необходимый для управления процессом оценки, считается гиперпараметром (например, `max_depth` -- максимальная глубина, до которой будет построено каждое дерево) и указывается как аргумент соответствующего конструктора:\n",
    "```python\n",
    "dt = DecisionTreeClassifier(random_state = 0, \n",
    "                            max_depth = 3)\n",
    "```   \n",
    "- трансформаторы (transformer): некоторые оценщики могут трансформировать набор данных: они называются **трансформаторами**. Трансформация выполняется методом `.transform()`, которому в параметре передается набор данных, подлежащий трансформации. Он возвращает трансформированный набор данных. Трансформация обучно использует параметры, полученный в методе `.fit()`. Все трансформаторы имеют удобный метод `.fit_transform()`, который представляет собой эквивалент последовательного вызова методов `.fit()` и `.transform()`:\n",
    "```python\n",
    "X_train_std = scaler.transform(X_train)\n",
    "```  \n",
    "- прогнозаторы (predictor): некоторые оценщики способны вырабатывать прогнозы, имея набор данных; они называются **прогнозаторами**. Прогнозатор располагает методом `.predict()`, который принимает набор методов с **новыми образцами** и возвращает набор данных с соответствующими прогнозами. В некоторых прогнозаторах есть также метод `.predict_proba()`, возвращающий распределение объекта на заданном множестве классов.  \n",
    "\n",
    "Прогнозатор также имеет метод `.score()`, измеряющий качество прогнозов.\n",
    "```python\n",
    "X_train_std = scaler.transform(X_train)\n",
    "dt.score(X_test, y_test)\n",
    "``` \n",
    "\n",
    "Построение модели, которая слишком сложна для имеющегося объема информации называется переобучением (overfitting). Переобучение происходит, когда модель слишком точно подстраивается под особенности обучающего набора и получается модель, которая хорошо работает на обучающем наборе, но не умеет обобщать результат на новые данные.\n",
    "\n",
    "Если модель слишком проста, то возможно она не охватила все многообразие и изменчивость данных, и модель будет плохо работать даже на обучающем наборе. Выбор слишком простой модели называется недообучением (underfitting)."
   ],
   "metadata": {
    "id": "NUAQY4NfpNZC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "#загрузка классификаторов \n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree # дерево решений\n",
    "from sklearn.ensemble import RandomForestClassifier #случайный лес\n",
    "from sklearn.linear_model import LogisticRegression # логистическая регресси\n",
    "from sklearn.svm import SVC # метод опорных векторов\n",
    "from sklearn.linear_model import SGDClassifier # стохастический градиентный спуск\n",
    "\n",
    "#метрики\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score \n",
    "from sklearn.metrics import classification_report  \n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "-MbIoMctpNCL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_excel('/content/med_set_clear_azot.xlsx')\n",
    "df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "1uRPE5-v5Tps",
    "outputId": "02db14a5-dc7d-401b-c7ff-400c63205c3a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   болезнь  пол  Возраст  Лейкоциты  Общий белок  Холестерин общий  \\\n",
       "0        0  жен       57        8.9        64.62              4.97   \n",
       "1        0  муж       60        6.2        69.00              5.69   \n",
       "2        0  муж       50        7.6        66.55              6.64   \n",
       "3        0  муж       54        6.6        68.25              5.69   \n",
       "4        0  жен       49        6.3        64.62              5.69   \n",
       "\n",
       "   Коэффициент атерогенности   ЛПНП  ЛПОНП  КДО  КСО     ИМТ  Глюкоза  \\\n",
       "0                      3.430  3.420   0.43  105   45  26.545     6.40   \n",
       "1                      3.405  3.445   0.55  105   45  26.545     5.56   \n",
       "2                      4.050  4.610   0.71  119   45  26.545     5.20   \n",
       "3                      3.405  3.445   0.55  134   55  26.545     4.50   \n",
       "4                      3.405  2.050   0.55  105   45  26.545     5.20   \n",
       "\n",
       "   β-катенин  Склеростин  WIF-1  DVL-1  GSK-3β  GSK-3α   Азот  \n",
       "0        462         270   1930   1852     245     120  10.80  \n",
       "1        432         232   2170    574     500     105   9.20  \n",
       "2        402         250   2170    625     340     110   9.20  \n",
       "3        790         160   2175   1852     430     110   8.95  \n",
       "4        585         160   1450    185     500     110   9.15  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-d2d9453b-3703-4159-8f4a-42058ac09d67\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>болезнь</th>\n",
       "      <th>пол</th>\n",
       "      <th>Возраст</th>\n",
       "      <th>Лейкоциты</th>\n",
       "      <th>Общий белок</th>\n",
       "      <th>Холестерин общий</th>\n",
       "      <th>Коэффициент атерогенности</th>\n",
       "      <th>ЛПНП</th>\n",
       "      <th>ЛПОНП</th>\n",
       "      <th>КДО</th>\n",
       "      <th>КСО</th>\n",
       "      <th>ИМТ</th>\n",
       "      <th>Глюкоза</th>\n",
       "      <th>β-катенин</th>\n",
       "      <th>Склеростин</th>\n",
       "      <th>WIF-1</th>\n",
       "      <th>DVL-1</th>\n",
       "      <th>GSK-3β</th>\n",
       "      <th>GSK-3α</th>\n",
       "      <th>Азот</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>жен</td>\n",
       "      <td>57</td>\n",
       "      <td>8.9</td>\n",
       "      <td>64.62</td>\n",
       "      <td>4.97</td>\n",
       "      <td>3.430</td>\n",
       "      <td>3.420</td>\n",
       "      <td>0.43</td>\n",
       "      <td>105</td>\n",
       "      <td>45</td>\n",
       "      <td>26.545</td>\n",
       "      <td>6.40</td>\n",
       "      <td>462</td>\n",
       "      <td>270</td>\n",
       "      <td>1930</td>\n",
       "      <td>1852</td>\n",
       "      <td>245</td>\n",
       "      <td>120</td>\n",
       "      <td>10.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>муж</td>\n",
       "      <td>60</td>\n",
       "      <td>6.2</td>\n",
       "      <td>69.00</td>\n",
       "      <td>5.69</td>\n",
       "      <td>3.405</td>\n",
       "      <td>3.445</td>\n",
       "      <td>0.55</td>\n",
       "      <td>105</td>\n",
       "      <td>45</td>\n",
       "      <td>26.545</td>\n",
       "      <td>5.56</td>\n",
       "      <td>432</td>\n",
       "      <td>232</td>\n",
       "      <td>2170</td>\n",
       "      <td>574</td>\n",
       "      <td>500</td>\n",
       "      <td>105</td>\n",
       "      <td>9.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>муж</td>\n",
       "      <td>50</td>\n",
       "      <td>7.6</td>\n",
       "      <td>66.55</td>\n",
       "      <td>6.64</td>\n",
       "      <td>4.050</td>\n",
       "      <td>4.610</td>\n",
       "      <td>0.71</td>\n",
       "      <td>119</td>\n",
       "      <td>45</td>\n",
       "      <td>26.545</td>\n",
       "      <td>5.20</td>\n",
       "      <td>402</td>\n",
       "      <td>250</td>\n",
       "      <td>2170</td>\n",
       "      <td>625</td>\n",
       "      <td>340</td>\n",
       "      <td>110</td>\n",
       "      <td>9.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>муж</td>\n",
       "      <td>54</td>\n",
       "      <td>6.6</td>\n",
       "      <td>68.25</td>\n",
       "      <td>5.69</td>\n",
       "      <td>3.405</td>\n",
       "      <td>3.445</td>\n",
       "      <td>0.55</td>\n",
       "      <td>134</td>\n",
       "      <td>55</td>\n",
       "      <td>26.545</td>\n",
       "      <td>4.50</td>\n",
       "      <td>790</td>\n",
       "      <td>160</td>\n",
       "      <td>2175</td>\n",
       "      <td>1852</td>\n",
       "      <td>430</td>\n",
       "      <td>110</td>\n",
       "      <td>8.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>жен</td>\n",
       "      <td>49</td>\n",
       "      <td>6.3</td>\n",
       "      <td>64.62</td>\n",
       "      <td>5.69</td>\n",
       "      <td>3.405</td>\n",
       "      <td>2.050</td>\n",
       "      <td>0.55</td>\n",
       "      <td>105</td>\n",
       "      <td>45</td>\n",
       "      <td>26.545</td>\n",
       "      <td>5.20</td>\n",
       "      <td>585</td>\n",
       "      <td>160</td>\n",
       "      <td>1450</td>\n",
       "      <td>185</td>\n",
       "      <td>500</td>\n",
       "      <td>110</td>\n",
       "      <td>9.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2d9453b-3703-4159-8f4a-42058ac09d67')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d2d9453b-3703-4159-8f4a-42058ac09d67 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d2d9453b-3703-4159-8f4a-42058ac09d67');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X = df.drop(columns = ['болезнь', 'пол'])\n",
    "y = df.болезнь"
   ],
   "metadata": {
    "id": "UcBnmMgjusEe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  \n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 42)"
   ],
   "metadata": {
    "id": "vmNzWDAMvTrh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()"
   ],
   "metadata": {
    "id": "Okau0MnbtpcO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "scaler.fit(X_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6lRECnEzhJV",
    "outputId": "cb67274b-6a65-4019-822b-2091384160a4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ],
   "metadata": {
    "id": "j9eZRdnxy6UO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ],
   "metadata": {
    "id": "FYKtAoFv2WXT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_std, y_train)\n",
    "dt.score(X_test_std, y_test)\n",
    "#plot_tree(dt)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JAi6eJAq23Xp",
    "outputId": "d4c5e010-b565-43dd-ac71-adb6a29b3c8b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dt.predict(X_test_std[0:2])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nY3IFcTo5oN3",
    "outputId": "a58f806f-869f-469e-cd64-26492e0f9955"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_test"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ek11Cg8b8Igm",
    "outputId": "4c3dd5a4-5dae-439e-caff-f8e2649ce1e3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "13    0\n",
       "45    1\n",
       "47    1\n",
       "44    1\n",
       "17    0\n",
       "27    1\n",
       "26    1\n",
       "25    1\n",
       "31    1\n",
       "19    0\n",
       "12    0\n",
       "4     0\n",
       "34    1\n",
       "8     0\n",
       "3     0\n",
       "Name: болезнь, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_train_std"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcuRk-Ib13Ng",
    "outputId": "e646778b-1ca7-4aef-ea0d-bafa82838467"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1.06597666e-01, -1.02348173e+00, -7.38289223e-01,\n",
       "         1.66715312e+00,  1.00687462e+00,  1.63360709e+00,\n",
       "         1.21711828e+00, -1.97868316e+00, -1.19542802e+00,\n",
       "        -3.36193438e-01, -9.30396233e-01,  5.65297390e-01,\n",
       "         7.89544024e-01, -5.39649484e-01,  1.78757461e+00,\n",
       "        -7.06507577e-01, -2.25539267e-01,  3.75443138e-01],\n",
       "       [ 1.31470455e+00,  1.80788243e+00,  1.42443938e+00,\n",
       "        -1.41083343e+00, -2.05503857e+00, -1.44954215e+00,\n",
       "        -2.17130508e+00, -1.28690704e+00, -8.83577231e-01,\n",
       "        -3.36193438e-01,  1.17756502e+00, -6.55695439e-01,\n",
       "        -1.04827153e+00,  7.11810259e-01, -1.22484413e+00,\n",
       "        -9.20093152e-01, -2.25539267e-01, -9.17933662e-01],\n",
       "       [-1.35023711e-01,  1.63864529e-01, -3.48288984e-01,\n",
       "        -1.36696664e+00, -1.29232373e+00, -1.14039168e+00,\n",
       "        -1.95502274e+00,  5.29005265e-01,  2.33888091e+00,\n",
       "         2.07463699e+00,  4.74911271e-01, -1.51354816e+00,\n",
       "         6.44996733e-01, -2.29695136e+00, -1.24213700e+00,\n",
       "        -9.20093152e-01, -8.86602637e-01, -8.61699888e-01],\n",
       "       [-1.46394128e+00, -2.62362333e-01,  5.68464825e-01,\n",
       "         8.33684076e-01,  5.86828764e-01,  8.56553219e-01,\n",
       "         9.28741822e-01, -3.30628291e-02, -1.55925394e-01,\n",
       "         2.07463699e+00,  1.17756502e+00, -9.25651257e-02,\n",
       "        -7.79826559e-01,  1.56364420e+00,  1.24284906e+00,\n",
       "         1.62073760e-01,  4.35524102e-01, -1.02477783e+00],\n",
       "       [-1.35023711e-01, -7.96936780e-02,  5.38075196e-01,\n",
       "        -1.11838816e+00, -6.29093440e-01, -1.16545794e+00,\n",
       "         6.36124536e-02,  1.52343343e+00,  3.63825919e-01,\n",
       "        -3.36193438e-01, -6.49334732e-01, -1.40829016e+00,\n",
       "        -6.35279269e-01,  4.59415016e-01, -8.35754451e-01,\n",
       "        -5.64117194e-01, -1.54766601e+00, -6.03024528e-01],\n",
       "       [-1.22231991e+00, -1.02348173e+00,  5.12750505e-01,\n",
       "         7.82506153e-01,  5.31559573e-01,  8.14776129e-01,\n",
       "         7.12459480e-01,  1.35048940e+00, -1.55925394e-01,\n",
       "        -3.36193438e-01, -2.05464224e+00,  8.54756897e-01,\n",
       "         6.03697508e-01, -1.04443997e+00, -2.30503845e-01,\n",
       "         1.62073760e-01,  4.35524102e-01,  1.13459909e+00],\n",
       "       [-8.59887842e-01,  1.16406496e-02,  1.58204833e-01,\n",
       "         2.12237860e-01,  2.93902052e-01,  1.22873794e-04,\n",
       "         6.36124536e-02, -1.33014305e+00, -1.19542802e+00,\n",
       "        -3.36193438e-01,  1.23584395e-01, -5.13597136e-01,\n",
       "        -8.83074624e-01, -7.60495321e-01, -3.60200403e-01,\n",
       "        -9.20093152e-01, -2.25539267e-01,  1.21894975e+00],\n",
       "       [ 7.10651109e-01, -5.97254868e-01,  1.58204833e-01,\n",
       "        -8.25942878e-01,  2.93902052e-01, -7.30976201e-01,\n",
       "        -1.16198749e+00,  5.29005265e-01,  1.19542802e+00,\n",
       "         2.07463699e+00, -1.07092698e+00,  1.54419681e+00,\n",
       "         5.83047895e-01,  1.24815015e+00,  5.39029070e-01,\n",
       "         7.17396254e-01, -1.81209135e+00, -4.39946584e-01],\n",
       "       [-2.18880542e+00,  1.16854213e+00,  1.31807567e+00,\n",
       "         3.14593707e-01, -1.64832235e-01,  3.88649811e-01,\n",
       "        -5.85234573e-01,  7.88421309e-01,  2.59875656e-01,\n",
       "         2.07463699e+00,  3.34380521e-01,  7.60024695e-01,\n",
       "        -7.79826559e-01,  1.24815015e+00,  1.24284906e+00,\n",
       "         2.19029913e-01,  4.35524102e-01, -9.74167436e-01],\n",
       "       [-1.46394128e+00, -2.62362333e-01,  5.68464825e-01,\n",
       "         8.33684076e-01,  5.86828764e-01,  8.56553219e-01,\n",
       "         9.28741822e-01, -3.30628291e-02, -1.55925394e-01,\n",
       "         2.07463699e+00,  1.17756502e+00, -9.25651257e-02,\n",
       "        -7.79826559e-01,  1.56364420e+00,  1.24284906e+00,\n",
       "         1.62073760e-01,  4.35524102e-01, -1.17098564e+00],\n",
       "       [ 1.19389386e+00, -3.84141437e-01, -1.68036772e+00,\n",
       "        -3.14163641e-01,  3.21536647e-01, -2.07656712e-02,\n",
       "        -8.01516915e-01, -3.30628291e-02, -1.55925394e-01,\n",
       "        -3.36193438e-01,  1.59915727e+00,  1.81105681e-01,\n",
       "         1.63617815e+00, -2.97770710e-01,  1.78757461e+00,\n",
       "         5.03810679e-01,  1.75765084e+00,  1.69693682e+00],\n",
       "       [-1.35023711e-01,  2.20366451e+00, -1.96906920e+00,\n",
       "         7.60572757e-01,  1.20584370e+00,  9.48462817e-01,\n",
       "         6.40365366e-01, -8.11310960e-01, -4.67776181e-01,\n",
       "        -1.36239213e+00,  3.34380521e-01,  1.52840811e+00,\n",
       "        -9.45023463e-01,  7.95942006e-01,  4.42188973e-01,\n",
       "        -4.21726811e-01, -2.25539267e-01, -1.05851810e+00],\n",
       "       [-1.35023711e-01,  2.20366451e+00, -1.96906920e+00,\n",
       "         7.60572757e-01,  1.20584370e+00,  9.48462817e-01,\n",
       "         6.40365366e-01, -8.11310960e-01, -4.67776181e-01,\n",
       "        -1.36239213e+00,  3.34380521e-01,  1.52840811e+00,\n",
       "        -9.45023463e-01,  7.95942006e-01,  4.42188973e-01,\n",
       "        -4.21726811e-01, -2.25539267e-01, -3.27479036e-01],\n",
       "       [ 1.19389386e+00,  1.63864529e-01,  5.73529763e-01,\n",
       "        -1.02140814e-01, -6.29093440e-01, -1.62807777e-01,\n",
       "        -7.29422801e-01, -1.24367103e+00, -1.19542802e+00,\n",
       "        -3.36193438e-01, -6.49334732e-01,  8.81071398e-01,\n",
       "        -6.35279269e-01,  1.15350193e+00,  6.60079191e-01,\n",
       "         1.47834721e-01,  1.75765084e+00,  1.25831339e+00],\n",
       "       [ 7.10651109e-01, -1.02348173e+00,  1.58204833e-01,\n",
       "         2.12237860e-01,  2.93902052e-01,  1.22873794e-04,\n",
       "         6.36124536e-02,  1.39881200e-01,  6.75676706e-01,\n",
       "        -3.36193438e-01,  5.33190200e-02, -3.09582360e-03,\n",
       "        -6.35279269e-01,  1.40589717e+00,  3.48807451e-01,\n",
       "        -1.36946045e-01,  4.35524102e-01, -4.96180358e-01],\n",
       "       [ 9.52272486e-01,  8.94539150e-01,  9.93919631e-01,\n",
       "        -1.11838816e+00, -6.29093440e-01, -1.16545794e+00,\n",
       "        -8.73611029e-01,  1.26401739e+00,  8.83577231e-01,\n",
       "        -3.36193438e-01,  1.31809577e+00, -3.13606931e-01,\n",
       "         1.22318590e+00, -7.57340381e-01,  2.81365240e-01,\n",
       "        -7.06507577e-01, -2.25539267e-01,  9.92360716e-03],\n",
       "       [-1.35023711e-01,  1.63864529e-01, -3.48288984e-01,\n",
       "        -1.36696664e+00, -1.29232373e+00, -1.14039168e+00,\n",
       "        -1.95502274e+00,  5.29005265e-01,  2.33888091e+00,\n",
       "         2.07463699e+00,  4.74911271e-01, -1.51354816e+00,\n",
       "         6.44996733e-01, -2.29695136e+00, -1.24213700e+00,\n",
       "        -9.20093152e-01, -8.86602637e-01,  9.92360716e-03],\n",
       "       [ 1.55632593e+00, -1.20615039e+00,  5.38075196e-01,\n",
       "         2.12237860e-01,  2.93902052e-01,  1.22873794e-04,\n",
       "         6.36124536e-02, -3.30628291e-02, -1.55925394e-01,\n",
       "        -3.36193438e-01,  4.18698971e-01,  2.32186770e-02,\n",
       "         8.51492863e-01, -4.53754682e-02, -4.22454751e-01,\n",
       "         4.13476545e+00, -2.25539267e-01,  7.97196442e-01],\n",
       "       [ 1.19389386e+00, -3.84141437e-01, -1.68036772e+00,\n",
       "        -3.14163641e-01,  3.21536647e-01, -2.07656712e-02,\n",
       "        -8.01516915e-01, -3.30628291e-02, -1.55925394e-01,\n",
       "        -3.36193438e-01,  1.59915727e+00,  1.81105681e-01,\n",
       "         1.63617815e+00, -2.97770710e-01,  1.78757461e+00,\n",
       "         5.03810679e-01,  1.75765084e+00,  1.02213154e+00],\n",
       "       [ 3.48219043e-01, -7.79923523e-01, -7.02834655e-01,\n",
       "         9.06795396e-01,  1.00687462e+00,  9.73529071e-01,\n",
       "         1.21711828e+00,  5.72241273e-01, -1.55925394e-01,\n",
       "        -3.36193438e-01, -8.72117304e-02, -1.34668327e-01,\n",
       "         1.22318590e+00, -4.53754682e-02, -3.34261091e-01,\n",
       "         1.85651932e+00,  4.35524102e-01,  7.97196442e-01],\n",
       "       [ 1.31470455e+00,  1.80788243e+00,  1.42443938e+00,\n",
       "        -1.41083343e+00, -2.05503857e+00, -1.44954215e+00,\n",
       "        -2.17130508e+00, -1.28690704e+00, -8.83577231e-01,\n",
       "        -3.36193438e-01,  1.17756502e+00, -6.55695439e-01,\n",
       "        -1.04827153e+00,  7.11810259e-01, -1.22484413e+00,\n",
       "        -9.20093152e-01, -2.25539267e-01, -5.24297245e-01],\n",
       "       [ 1.19389386e+00, -2.62362333e-01,  1.42443938e+00,\n",
       "        -9.06365329e-01, -1.18178535e+00, -9.98349577e-01,\n",
       "         1.35706568e-01,  7.88421309e-01,  2.02703012e+00,\n",
       "        -3.36193438e-01, -6.49334732e-01, -1.29405427e-01,\n",
       "        -1.00697230e+00, -5.39649484e-01, -1.22484413e+00,\n",
       "        -4.21726811e-01, -2.25539267e-01, -3.83712810e-01],\n",
       "       [-1.22231991e+00, -1.02348173e+00,  5.12750505e-01,\n",
       "         7.82506153e-01,  5.31559573e-01,  8.14776129e-01,\n",
       "         7.12459480e-01,  1.35048940e+00, -1.55925394e-01,\n",
       "        -3.36193438e-01, -2.05464224e+00,  8.54756897e-01,\n",
       "         6.03697508e-01, -1.04443997e+00, -2.30503845e-01,\n",
       "         1.62073760e-01,  4.35524102e-01,  1.13459909e+00],\n",
       "       [-1.70556266e+00, -8.10368299e-01, -1.15361415e+00,\n",
       "         1.97422066e+00,  2.15647379e+00,  1.86755880e+00,\n",
       "         9.28741822e-01, -3.30628291e-02, -1.55925394e-01,\n",
       "        -1.26419130e+00, -1.21145773e+00,  2.75837883e-01,\n",
       "         1.84267428e+00, -5.39649484e-01,  7.55190001e-01,\n",
       "         5.03810679e-01,  4.35524102e-01, -1.03040121e+00],\n",
       "       [ 2.27408355e-01, -1.10138454e-01,  1.58204833e-01,\n",
       "         2.12237860e-01,  2.93902052e-01,  1.22873794e-04,\n",
       "         6.36124536e-02, -1.80573913e+00, -1.19542802e+00,\n",
       "        -3.36193438e-01,  1.23584395e-01, -1.65564646e+00,\n",
       "        -8.41775398e-01,  5.24276882e-02, -8.96279512e-01,\n",
       "        -8.48897960e-01,  1.75765084e+00,  8.25313329e-01],\n",
       "       [ 3.48219043e-01, -7.79923523e-01, -7.02834655e-01,\n",
       "         9.06795396e-01,  1.00687462e+00,  9.73529071e-01,\n",
       "         1.21711828e+00,  5.72241273e-01, -1.55925394e-01,\n",
       "        -3.36193438e-01, -8.72117304e-02, -1.34668327e-01,\n",
       "         1.22318590e+00, -4.53754682e-02, -3.34261091e-01,\n",
       "         1.85651932e+00,  4.35524102e-01,  1.78624929e-01],\n",
       "       [-1.22231991e+00, -1.02348173e+00,  5.12750505e-01,\n",
       "         7.82506153e-01,  5.31559573e-01,  8.14776129e-01,\n",
       "         7.12459480e-01,  1.35048940e+00, -1.55925394e-01,\n",
       "        -3.36193438e-01, -2.05464224e+00,  8.54756897e-01,\n",
       "         6.03697508e-01, -1.04443997e+00, -2.30503845e-01,\n",
       "         1.62073760e-01,  4.35524102e-01,  1.78624929e-01],\n",
       "       [-7.39077153e-01,  1.33419753e-01, -1.66010797e+00,\n",
       "        -2.90294945e-02, -3.52747484e-01,  2.10114188e-02,\n",
       "        -3.68952231e-01, -6.38366931e-01, -3.63825919e-01,\n",
       "        -3.36193438e-01,  1.17756502e+00,  5.81086090e-01,\n",
       "        -8.83074624e-01, -2.55704837e-01, -3.34261091e-01,\n",
       "        -3.50531620e-01, -2.25539267e-01, -1.01353108e+00],\n",
       "       [ 2.27408355e-01, -1.10138454e-01,  1.58204833e-01,\n",
       "         2.12237860e-01,  2.93902052e-01,  1.22873794e-04,\n",
       "         6.36124536e-02, -1.80573913e+00, -1.19542802e+00,\n",
       "        -3.36193438e-01,  1.23584395e-01, -1.65564646e+00,\n",
       "        -8.41775398e-01,  5.24276882e-02, -8.96279512e-01,\n",
       "        -8.48897960e-01,  1.75765084e+00,  2.82161230e+00],\n",
       "       [ 2.27408355e-01, -5.36365316e-01, -1.02699070e+00,\n",
       "         1.28697426e+00,  6.86313308e-01,  1.10721576e+00,\n",
       "         1.21711828e+00, -3.35714880e-01, -5.19751313e-02,\n",
       "        -3.36193438e-01,  6.15442022e-01,  1.06527290e+00,\n",
       "        -7.38527333e-01,  1.09040312e+00,  1.78757461e+00,\n",
       "         1.47834721e-01, -8.86602637e-01,  1.02213154e+00],\n",
       "       [ 1.19389386e+00, -2.62362333e-01,  1.42443938e+00,\n",
       "        -9.06365329e-01, -1.18178535e+00, -9.98349577e-01,\n",
       "         1.35706568e-01,  7.88421309e-01,  2.02703012e+00,\n",
       "        -3.36193438e-01, -6.49334732e-01, -1.29405427e-01,\n",
       "        -1.00697230e+00, -5.39649484e-01, -1.22484413e+00,\n",
       "        -4.21726811e-01, -2.25539267e-01, -1.28345319e+00],\n",
       "       [-1.35023711e-01, -7.96936780e-02,  5.38075196e-01,\n",
       "        -1.11838816e+00, -6.29093440e-01, -1.16545794e+00,\n",
       "         6.36124536e-02,  1.52343343e+00,  3.63825919e-01,\n",
       "        -3.36193438e-01, -6.49334732e-01, -1.40829016e+00,\n",
       "        -6.35279269e-01,  4.59415016e-01, -8.35754451e-01,\n",
       "        -5.64117194e-01, -1.54766601e+00, -9.74167436e-01],\n",
       "       [-8.59887842e-01, -9.01702626e-01,  2.84828288e-01,\n",
       "         8.11750681e-01,  6.31044117e-01,  8.56553219e-01,\n",
       "         8.56647708e-01, -3.30628291e-02, -1.55925394e-01,\n",
       "        -3.90203895e-01, -6.49334732e-01,  1.90733692e+00,\n",
       "         1.84267428e+00,  5.33030295e-01,  2.88282390e-01,\n",
       "         1.76312798e-01, -2.20872938e+00, -1.01353108e+00],\n",
       "       [-2.55834399e-01,  2.20366451e+00,  3.15813792e-02,\n",
       "        -2.15656889e+00, -1.98871554e+00, -2.26837311e+00,\n",
       "         9.28741822e-01, -3.30628291e-02, -1.50727881e+00,\n",
       "        -3.36193438e-01, -3.68273231e-01, -1.57670296e+00,\n",
       "        -8.83074624e-01, -1.45458224e+00, -1.31130850e+00,\n",
       "        -5.64117194e-01, -8.86602637e-01, -3.83712810e-01]])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.болезнь.value_counts()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GzPcOwUt-_u",
    "outputId": "bb948d95-b07f-4d7e-fac8-a873f4df0c33"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    25\n",
       "0    24\n",
       "Name: болезнь, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "У класса `DecisionTreeClassifier` достаточно [много параметров](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier). Перечислим наиболее важные из них:\n",
    "\n",
    "|Параметр|Комментарий|\n",
    "|--:|:--|\n",
    "|`criterion`|задается метод разделения в узле (критерий Джини, энтропия)|\n",
    "|`max_depth`|максимальная глубина разбиения|\n",
    "|`min_samples_split`|минимальное число образцов, которые должны присутствовать в узле, прежде чем, его можно будет расщепить|\n",
    "|`max_features`|максимальное число признаков, которые оцениваются при расщеплении|\n",
    "\n",
    "Сказать про важность признаков.\n",
    "\n",
    "Литература:\n",
    "1. Харрисон М. Машинное обучение: карманный справочник. Краткое руководство по методам структурированного машинного обучения на Python/ - СПб.: ООО \"Диалектика\", 2020. -- 320 с. "
   ],
   "metadata": {
    "id": "n7cDE9LOyndl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В библиотеке sklearn есть и другие классификаторы: \n",
    "- SGD Classifier (SGD) - линейный классификатор с SGD-обучением (stochastic gradient descent - стохастический градиентный спуск);\n",
    "- Support Vector Machines (SVM) - метод опорных векторов (kernel = 'linear');\n",
    "- Random Forest Classifier (RF) - случайный лес (используются деревья решений);\n",
    "- Gaussian process classification (GP) - гауссовская классификация (основана на аппроксимации Лапласа);\n",
    "- AdaBoost (Adaptive Boosting) Classifier (AB) - адаптивное усиление;\n",
    "- Decision tree classifier (DT) - дерево решений;\n",
    "- Logistic Regression (LR) - логистическая регрессия;\n",
    "- Gaussian Naive Bayes (NB) - гауссовский наивный байесовский классификатор;\n",
    "- K-Nearest Neighbors (KNN) - метод K-ближайших соседей.\n",
    "\n",
    "Рассмотрим наиболее распространенные из них.\n",
    "\n",
    "**Random Forest Classifier (RF)** -- случайный лес, совокупность деревьев\n",
    "решений.\n",
    "\n",
    "В библиотеке `scikit-learn` есть такая [реализация RF](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html):\n",
    "\n",
    "```python\n",
    "class sklearn.ensemble.RandomForestClassifier(n_estimators=100, \n",
    "criterion='gini', max_depth=None, min_samples_split=2, \n",
    "min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, \n",
    "max_samples=None)\n",
    "```\n",
    "Стандартная схема применения \n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import classification_report \n",
    "# далее - (X, y) - обучение, (X2, y2) - контроль\n",
    "model =  RandomForestRegressor(n_estimators = 5,\n",
    "                               max_depth = 4, \n",
    "                               random_state = 0)\n",
    "model.fit(X, y) # обучение\n",
    "a = model.predict(X2) # предсказание\n",
    "\n",
    "print('Метрики качества для RandomForestClassifier', '\\n', classification_report(y2, a))\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Ключевые параметры метода\n",
    "\n",
    "|Параметр|Комментарий|\n",
    "|--:|:--|\n",
    "|`n_estimators`|число деревьев в лесе|\n",
    "|`max_features`|максимальное число признаков, которые оцениваются при расщеплении -- по умолчанию $\\sqrt{n}$. Больше лучше|\n",
    "|`criterion`|задается метод разделения в узле (критерий Джини, энтропия)|\n",
    "|`max_depth`|максимальная глубина разбиения. Больше лучше|\n",
    "|`min_samples_split`|минимальное число образцов, которые должны присутствовать в узле, прежде чем, его можно будет расщепить|\n",
    "\n",
    "\n",
    "Рекомендации по использованию классификатора: \n",
    "- Добавьте больше деревьев (`n_еstimatоrs`);\n",
    "- Используйте меньшую глубину обучения `max_depth`.\n"
   ],
   "metadata": {
    "id": "Y7Lkwx-15Asv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "rnd = RandomForestClassifier(random_state=0 )\n",
    "rnd.fit(X_train_std, y_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VTdnriPNynBI",
    "outputId": "65071954-6337-4d83-db88-6fbc85c135e6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "rnd.score(X_test_std, y_test)\n",
    "y_pred = rnd.predict(X_test_std) "
   ],
   "metadata": {
    "id": "lwMY3oM6-DPU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vF5_zhPJ-h_3",
    "outputId": "9b41e41e-0b71-4a6f-ec6e-034eac5a3dea"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "[**Логистическая регрессия**](https://medium.com/nuances-of-programming/%D0%BF%D0%BE%D1%88%D0%B0%D0%B3%D0%BE%D0%B2%D0%BE%D0%B5-%D0%BF%D0%BE%D1%81%D1%82%D1%80%D0%BE%D0%B5%D0%BD%D0%B8%D0%B5-%D0%BB%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B9-%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%B8-%D0%B2-python-a7c650ae77c2) -- статистическая модель, используемая для прогнозирования вероятности возникновения некоторого события путем его сравнения с логистической кривой. \n",
    "\n",
    "В библиотеке `scikit-learn` есть такая реализация [логистической регрессии](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html):\n",
    "\n",
    "```python\n",
    "class sklearn.linear_model.LogisticRegression(penalty='l2', \n",
    "dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "class_weight=None, random_state=None, solver='lbfgs', max_iter=100, \n",
    "multi_class='auto', verbose=0, warm_start=False, n_jobs=None, \n",
    "l1_ratio=None)\n",
    "```\n",
    "\n",
    "Ключевые параметры метода\n",
    "\n",
    "|Параметр|Комментарий|\n",
    "|--:|:--|\n",
    "|`C`|параметр, контролирующий регуляризацию|\n",
    "|`penalty`|норма штрафа|\n",
    "|`max_iter`|максимальное количество итераций|\n",
    "\n"
   ],
   "metadata": {
    "id": "TFOlPz__DpUs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train_std, y_train)\n",
    "print(lr.score(X_test_std, y_test))\n",
    "y_pred = lr.predict(X_test_std)"
   ],
   "metadata": {
    "id": "abnjyLDYDlpH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c1cb3ca4-e3dc-4c6c-f576-0197cb33692e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9333333333333333\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-4.26678759e-01,  6.21795146e-01, -2.38719944e-01,\n",
       "        -4.80192605e-04, -2.21845245e-01, -3.24244753e-02,\n",
       "        -7.94273625e-02, -8.18787108e-01,  7.77383207e-01,\n",
       "         4.67843164e-01,  7.53913579e-02,  7.16634234e-01,\n",
       "        -2.03038347e-01,  3.81772207e-02, -3.48327474e-01,\n",
       "         3.74416880e-02,  7.72616972e-02, -1.73226420e+00]])"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Метод опорных векторов** -- классификатор, в рамках которого строится линия (плоскость, гиперплоскость) между разными классами такая, что максимизируется расстояние от линии до точек классов.\n",
    "\n",
    "Реализация в Python\n",
    "\n",
    "```python\n",
    "class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', \n",
    "coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "cache_size=200, class_weight=None, verbose=False, max_iter=-1, \n",
    "decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "```\n",
    "\n",
    "Ключевые параметры метода\n",
    "\n",
    "|Параметр|Комментарий|\n",
    "|--:|:--|\n",
    "|`C`|параметр, контролирующий регуляризацию|\n",
    "|`kernel`|тип ядра, который будет использоваться в алгоритме|\n",
    "|`degree`|степень полиномиальной функции ядра|\n",
    "|`gamma`|коэффициент ядра для «rbf», «poly» и «sigmoid»|\n"
   ],
   "metadata": {
    "id": "U5bVBhEsetU0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "svc = SVC(random_state=42)\n",
    "svc.fit(X_train_std, y_train)\n",
    "svc.score(X_test_std, y_test)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p13mAw_4esz5",
    "outputId": "c31f6603-a43b-4640-f7ea-2495201c6083"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "MCAPU_EleQH6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Поиск значений гиперпараметров по сетке `GridSearchCV()`\n",
    "\n",
    "```python\n",
    "class sklearn.model_selection.GridSearchCV(estimator, param_grid,  \n",
    "scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, \n",
    "pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "```\n",
    "\n",
    "Изменение параметров модели может принципиально повлиять на ее качество. Например, модель может переобучиться. Перебор этих параметров вручную может занять значительное количество времени. Для автоматического подбора параметров используется класс [`GridSearchCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "Процесс отбора параметров и оценки модели с помощью `GridSearchCV`.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=16s-bNVZrdFA_PGSu8dty1AdIk1llms3-' width=\"450\" height=\"300\" />\n",
    "<figcaption>Процесс отбора параметров и оценки модели</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "Для того, чтобы воспользоваться классом `GridSearchCV`, сначала необходимо указать искомые параметры с помощью словаря. Ключами словаря являются имена настраиваемых параметров, а значениями – тестируемые настройки параметров. `GridSearchCV` построит все необходимые модели.\n",
    "\n",
    "Процесс подгонки объекта `GridSearchCV` включает в себя не только\n",
    "поиск лучших параметров, но и автоматическое построение новой модели\n",
    "на всем обучающем наборе данных. Для ее построения используются\n",
    "параметры, которые дают наилучшее значение правильности\n",
    "перекрестной проверки. Построение и контроль новой модели осуществляется с использованием методов `.fit()`, `.predict()` и `.score()`.\n",
    "\n",
    "Перекрестная проверка (кросс-проверка, кроссвалидация) - метод оценки аналитической модели и её поведения на независимых данных. При оценке модели имеющиеся в наличии данные разбиваются на $k$ частей. Затем на $k−1$ частях данных производится обучение модели, а оставшаяся часть данных используется для тестирования. Процедура повторяется $k$ раз; в итоге каждая из $k$ частей данных используется для тестирования. В результате получается оценка эффективности выбранной модели с наиболее равномерным использованием имеющихся данных.\n",
    "\n",
    "Лучше оценку качества и соответствующие параметры можно вывести так   \n",
    "```python\n",
    "print ('best_score -- {}'.format(grid_searcher.best_score_))\n",
    "print ('best_params -- {}'.format(grid_searcher.best_params_))\n",
    "```"
   ],
   "metadata": {
    "id": "0gK0akMCCBCa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "svc_grid_search = GridSearchCV(\n",
    "    SVC(),\n",
    "    param_grid={\n",
    "        'kernel' : ['linear', 'rbf'],\n",
    "        'C' : [1, 3, 5, 10], #\n",
    "        'degree' : [3, 5],\n",
    "        'gamma' : [1, 3, 5, 10]\n",
    "    },\n",
    "    cv=5,\n",
    "    scoring='accuracy')"
   ],
   "metadata": {
    "id": "S1tnTVoq6XnM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "svc_grid_search.fit(X_train_std, y_train)"
   ],
   "metadata": {
    "id": "U2qtBRq_CAyM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4e4c889d-7650-4819-9902-7a88b37258c9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [1, 3, 5, 10], 'degree': [3, 5],\n",
       "                         'gamma': [1, 3, 5, 10], 'kernel': ['linear', 'rbf']},\n",
       "             scoring='accuracy')"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "svc_grid_search.score(X_test_std, y_test)\n",
    "y_pred = svc_grid_search.predict(X_test_std)"
   ],
   "metadata": {
    "id": "kl1X2B2e7SzW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "svc_grid_search.best_score_"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4Hy3PUZ7j4O",
    "outputId": "3fde1f99-7c71-4f95-80e9-ac6445a1a5eb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.880952380952381"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Метрики и оценка классификации](https://habr.com/ru/company/ods/blog/328372/)\n",
    "\n",
    "Матрица ошибок\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=16eVHRWPexiqIIitzCW6lX_Kbb40C5XpX' width=\"750\" height=\"100\" />\n",
    "<figcaption>Матрица ошибок</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Здесь $a(x)$ — это ответ алгоритма на объекте, а $y$ — истинная метка класса на этом объекте. Таким образом, ошибки классификации бывают двух видов: False Negative (FN) и False Positive (FP). P означает что классификатор определяет класс объекта как положительный (N — отрицательный). T значит что класс предсказан правильно (соответственно F — неправильно). Каждая строка в матрице ошибок представляет спрогнозированный класс, а каждый столбец — фактический класс.\n",
    "\n",
    "Метрики\n",
    "- `accuracy` (аккуратность) -- доля правильных ответов алгоритма\n",
    "$$\n",
    "accuracy = \\dfrac{TP+TN}{TP+TN+FP+FN}\n",
    "$$\n",
    "- `precision` (точность) -- доля правильных ответов модели в пределах класса\n",
    "$$\n",
    "precision = \\dfrac{TP}{TP+FP}\n",
    "$$\n",
    "- `recall` (полнота) -- это доля истинно положительных классификаций\n",
    "$$\n",
    "recall = \\dfrac{TP}{TP+FN}\n",
    "$$\n",
    "- `F-мера` -- гармоническое среднее точности и полноты\n",
    "$$\n",
    "F = 2\\cdot  \\dfrac{точность \\cdot полноста}{точность + полноста}.\n",
    "$$"
   ],
   "metadata": {
    "id": "eWgzx_978bPe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "             columns = ['прогноз для класса 0','прогноз для класса 1'], \n",
    "             index = ['истинный класс 0','истинный класс 1'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "YiJH3HTH8a8g",
    "outputId": "1594319d-b5da-46c3-9dcb-fc8da3bfba89"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  прогноз для класса 0  прогноз для класса 1\n",
       "истинный класс 0                     5                     2\n",
       "истинный класс 1                     1                     7"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-e1eb08f7-e6ef-4bff-9be7-704a0df986e9\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>прогноз для класса 0</th>\n",
       "      <th>прогноз для класса 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>истинный класс 0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>истинный класс 1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1eb08f7-e6ef-4bff-9be7-704a0df986e9')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e1eb08f7-e6ef-4bff-9be7-704a0df986e9 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e1eb08f7-e6ef-4bff-9be7-704a0df986e9');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dict_to_df = {'y_test': y_test, \n",
    "              'y_pred': y_pred}\n",
    "\n",
    "pd.DataFrame(dict_to_df)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "8RytY08i7pp5",
    "outputId": "aceca95f-d4de-48d8-81f5-7825112d3a90"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    y_test  y_pred\n",
       "13       0       0\n",
       "45       1       1\n",
       "47       1       1\n",
       "44       1       1\n",
       "17       0       0\n",
       "27       1       0\n",
       "26       1       1\n",
       "25       1       1\n",
       "31       1       1\n",
       "19       0       0\n",
       "12       0       0\n",
       "4        0       1\n",
       "34       1       1\n",
       "8        0       1\n",
       "3        0       0"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-d141e34f-38bd-4c44-a5a6-09795d36de56\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d141e34f-38bd-4c44-a5a6-09795d36de56')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d141e34f-38bd-4c44-a5a6-09795d36de56 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d141e34f-38bd-4c44-a5a6-09795d36de56');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Аккуратность (accuracy) = {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Точность (precision) = {}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Полнота (recall) = {}\".format(recall_score(y_test, y_pred)))\n",
    "print(\"F-мера (f-score) = {}\".format(f1_score(y_test, y_pred)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JoIEsvgRHFwp",
    "outputId": "aeb4b154-004c-4a4b-b1f0-4dab9e66f1cc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Аккуратность (accuracy) = 0.8\n",
      "Точность (precision) = 0.7777777777777778\n",
      "Полнота (recall) = 0.875\n",
      "F-мера (f-score) = 0.823529411764706\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print('Отчет о классификации', '\\n', classification_report(y_test, y_pred))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qO-IxyjHWMu",
    "outputId": "39bbcf15-a0bf-41c2-a4db-cc7bcb63da68"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Отчет о классификации \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77         7\n",
      "           1       0.78      0.88      0.82         8\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.81      0.79      0.80        15\n",
      "weighted avg       0.80      0.80      0.80        15\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Тема 7.3 Кластеризация: теория\n",
    "\n",
    "Содержательная постановка задачи кластеризации\n",
    "\n",
    "Задача кластеризации состоит в построении разбиения исследуемого множества объектов на группы, называемые кластерами, таким образом, чтобы в смысле установленной меры близости объекты одного кластера были весьма схожими друг с другом, а объекты разных кластеров существенно различались.\n",
    "\n",
    "Формальная постановка задачи кластеризации\n",
    "\n",
    "Пусть $O=\\{O_1,O_2,\\ldots, O_n\\}$ --- множество объектов, для\n",
    "каждого из которых $O_i\\in O$, $i=\\overline{1,n}$\\,, известна\n",
    "вектор-строка вида $x_i=(x_{i1},x_{i2},\\ldots, x_{ip})$, где\n",
    "$x_{ij}$ --- значение $j$-ого признака данного объекта,\n",
    "$j=\\overline{1,p}$. Пусть также задана функция $d(x_i,x_l)$,\n",
    "отражающая меру близости между объектами.\n",
    "\n",
    "\n",
    "\n",
    "Тогда для множества $O$ исследуемых объектов задача кластеризации\n",
    "состоит в построении множества\n",
    "$$\n",
    "\\mathcal{C}=\\{C_1,C_2,\\ldots, C_h\\},\n",
    "$$\n",
    "где $C_k$ --- кластер, содержащий близкие, в смысле заданной\n",
    "функции расстояния, объекты, т.е.\n",
    "$$\n",
    "C_k=\\{x_i,x_l\\,|\\,  d(x_i,x_l)<\\varepsilon; \\, i,l\n",
    "=\\overline{1,n}\\,\\}, \\quad k=\\overline{1,h}\\,.\n",
    "$$\n",
    "Здесь $\\varepsilon$ --- величина, характеризующая степень близости\n",
    "между двумя объектами. Если для двух любых объектов $O_i$ и $O_l$\n",
    "величина $d(x_i, x_l)$ меньше некоторого значения $\\varepsilon$,\n",
    "то говорят, что эти объекты близки в смысле заданной функции\n",
    "расстояния и их помещают в один кластер. В противном случае\n",
    "говорят, что объекты не схожи друг с другом и их помещают в разные\n",
    "кластеры.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=17Do8Jvj77cjieVcJxPlZPrm4aNN9OpBJ' width=\"500\" height=\"300\" />\n",
    "<figcaption>Исходное множество объектов</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=17Dc3KD7XK3N2-LPnjjHZsBT0_bbq_IEL' width=\"500\" height=\"300\" />\n",
    "<figcaption>Кластеризация исходного множества объектов </figcaption></center>\n",
    "</figure>\n",
    "\n",
    "Меры схожести\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=17EYvhQURMLEDERuH927L3wUT8FvRjXVE' width=\"650\" height=\"250\" />\n",
    "<figcaption>Меры схожести</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "Функционалы качества кластеризации\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=17N4tTgbmWkHUx-W_fm469DWR_UPxUUp6' width=\"600\" height=\"200\" />\n",
    "<figcaption>Функционалы качества</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "Типология алгоритмов кластеризации\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=17NmfQbcrDStH-kvP_6cpuMFfDrRFVFaW' width=\"600\" height=\"350\" />\n",
    "<figcaption>Алгоритмы кластеризации</figcaption></center>\n",
    "</figure>\n",
    "\n"
   ],
   "metadata": {
    "id": "nlpVdgCvA0fd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Тема 7.3 Кластеризация: практика\n",
    "\n"
   ],
   "metadata": {
    "id": "Ei9-WWJlP-_m"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подключение библиотек"
   ],
   "metadata": {
    "id": "CxG_OqDwmQOC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "id": "HW9nPfuDmLLV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_table('mobile.txt', \n",
    "                   encoding='1251', \n",
    "                   sep='\\t')\n",
    "df.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Отбор признаков"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_to_cluster = df.drop(columns = 'Код')\n",
    "df_to_cluster"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Нормализация данных\n",
    "\n",
    "\n",
    "[**Нормализацией**](https://wiki.loginom.ru/articles/data-normalization.html) называют метод предобработки числовых признаков в обучающих наборах данных с целью приведения их к некоторой общей шкале без потери информации о различии диапазонов.\n",
    "\n",
    "Необходимость нормализации вызвана тем, что разные признаки обучающего набора данных могут быть представлены в разных масштабах и изменяться в разных диапазонах. Например, возраст, который изменяется от 0 до 100, и доход, изменяющийся от нескольких тысяч до нескольких миллионов. То есть диапазоны изменения признаков «Возраст» и «Доход» различаются в тысячи раз.\n",
    "\n",
    "В этом случае возникает нарушение баланса между влиянием входных переменных, представленных в разных масштабах, на выходную переменную. Т.е. это влияние обусловлено не реальной зависимостью, а изменением масштаба. В результате, обучаемая модель может выявить [некорректные зависимости](https://habr.com/ru/company/ods/blog/325422/).\n",
    "\n",
    "Существует несколько основных методов нормализации.\n",
    "- минимаксная нормализация:\n",
    "$$\n",
    "x' = \\dfrac{x-x_{min}}{x_{max}-x_{min}}, \\quad x' \\in [0,1];\n",
    "$$\n",
    "\n",
    "$$\n",
    "x' = a+\\dfrac{x-x_{min}}{x_{max}-x_{min}} \\times (b-a), \\quad x' \\in [a,b].\n",
    "$$\n",
    "\n",
    "- максиминная нормализация: \n",
    "$$\n",
    "x' = \\dfrac{x_{max}-x}{x_{max}-x_{min}}, \\quad x' \\in [0,1];\n",
    "$$\n",
    "\n",
    "$$\n",
    "x' = a+\\dfrac{x_{max}-x}{x_{max}-x_{min}} \\times (b-a), \\quad x' \\in [a,b].\n",
    "$$\n",
    "\n",
    "- нормализация средним ($Z$-нормализация):\n",
    "$$\n",
    "x' = \\dfrac{x-\\mu_x}{\\sigma_x}.\n",
    "$$\n",
    "где $\\mu_x$ $\\sigma_x$ -- выборочное среднее и среднеквадратическое  отклонение, соответственно. \n",
    "\n",
    "Методы для нормализации реализованы в модуле [sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing): \n",
    "\n",
    "|Метод|Комментарий|\n",
    "|--:|:--|\n",
    "|`MaxAbsScaler()`|Преобразует данные по максимальному абсолютному значению|\n",
    "|`MinMaxScaler()`|Минимаксная нормализация|\n",
    "|`StandardScaler()`|Нормализация средним|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ресурсы по теме:\n",
    "1. [Data Preparation: полет нормальный – что такое нормализация данных и зачем она нужна](https://www.bigdataschool.ru/blog/%D0%BD%D0%BE%D1%80%D0%BC%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F-feature-transformation-data-preparation.html)\n",
    "2. [Масштабирование признаков](http://sebastianraschka.com/Articles/2014_about_feature_scaling.html)     "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df_to_cluster)\n",
    "df_to_fit = scaler.transform(df_to_cluster)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_to_fit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Иерархическая кластеризация: агломеративный алгоритм\n",
    "\n",
    "Существует два варианта иерархической кластеризации:\n",
    "\n",
    "1. Агломеративная, в которой алгоритм на каждой итерации объединяет два меньших кластера в один\n",
    "2. Дивизивная, в которой алгоритм на каждой итерации разбивает один кластер на два более мелких\n",
    "\n",
    "Мы рассмотрим аггломеративный подход к кластеризации.\n",
    "\n",
    "Опишем схематически алгоритм аггломеративной иерархической кластеризации:\n",
    "\n",
    "- Инициализируем наше множество кластеров, каждая точка считается свои кластером. То есть для выборки размера $N$ у нас на первой итерации будет $N$ кластеров. Также входным параметром алгоритму подается метрика расстояния между двумя кластерами. Самой популярной метрикой является расстояние Уорда.\n",
    "\n",
    "- На каждой итерации  мы объединяем два кластера в один. Объединяющиеся кластера выбираются в соответствии с наименьшим расстоянием Уорда. То есть в соответствии с выбранным нами расстоянием эти два кластера будут наиболее похожи и поэтому объединяются\n",
    "\n",
    "- Предыдущий шаг повторяется вплоть до объединения всех точек один кластер.\n",
    "\n",
    "В результате в данном подходе мы можем выбрать любое количество кластеров после завершения процедуры, просто остановив на нужном нам шаге. К тому же данный алгоритм гораздо менее чувствителен к выбору метрики между точками, тогда как другие алгоритмы сильно зависят от этого.\n",
    "\n",
    "Для визуализации иерархической кластеризации удобно строить дендрограммы, в которых разница между уровнями равна выбранному расстоянию объединяющихся на данном этапе кластеров.\n",
    "\n",
    "Посмотрим на иерархическую кластеризацию.\n",
    "\n",
    "Для изучания материала рекомендуется воспользоваться [ресурсом](https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/).    \n",
    "Иерархическая кластеризация реализована в модуле `scipy.cluster.hierarchy`.    \n",
    "Импортируем из этого модуля методы:    \n",
    "- `.linkage()` -- выполняет иерархическую (агломеративную) кластеризацию; \n",
    "- `.fcluster()` -- выполняет некоторое разбиение объектов на кластеры;\n",
    "- `.dendrogram()` -- строит дендрограмму.  \n",
    "\n",
    "Метод `.linkage()` имеет следующую спецификацию `linkage(y[, method, metric, optimal_ordering])`:    \n",
    "- y -- матрица попарных расстояний или исходных данных (в матрице не должно быть пробелов или категориальных значений)\n",
    "- method -- правило, по которому будут рассчитываться расстояния между кластерами:    \n",
    "    - `single`\n",
    "    - `complete`\n",
    "    - `average`\n",
    "    - `weighted`\n",
    "    - `centroid`\n",
    "    - `median`\n",
    "    - `ward`\n",
    "- metric -- метрика: `braycurtis`, `canberra`, `chebyshev`, `cityblock`, `correlation`, `cosine`, `dice`, `euclidean`, `hamming`, `jaccard`, `jensenshannon`, `kulsinski`, `mahalanobis`, `matching`, `minkowsk`, `rogerstanimoto`, `russellrao`, `seuclidean`, `sokalmichener`, `sokalsneath`, `sqeuclidean`, `yule`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mergings = linkage(df_to_fit, \n",
    "                   method='ward')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(df_to_fit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "mergings[:2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Дадим интерпретацию элементам массив связей кластера `Z`. В первом и втором столбцах массива `Z` указаны индексы кластеров (в том числе синглетонов), объединяющих на текущей итерации. В третьем столбце находится расстояние между кластерами. В четвертом столбце -- количество элементов в новом кластере. Например, строка Z[0] содержит следующее `[3419.000,  3697.000,  0.016,  2.000]`. Элементы этой строки показывают, что на первой (напомним, что индексация массивов начинается с 0) итерации алгоритма объединяются кластеры (здесь синглетоны -- кластер, состоящий из одного элемента) с номерами 3419 и 3697, расстояние между кластерами равно 0.016, количество элементов в кластере равно 2.     \n",
    "Напомним, что в исходном массиве число объектов 4492, проиндексированных от 0 до 4491. Если имеем индексы такие, что $idx \\geqslant len(X)$ соответствуют кластерам, которые объединились ранее и находятся в массиве связей кластера в строке $Z[idx-len(X)]$, где $len(X)=4491$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Визуализация: дендрограмма"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,7))\n",
    "dendrogram(mergings, \n",
    "            p = 7,\n",
    "            truncate_mode = 'lastp',\n",
    "           leaf_rotation = 0,\n",
    "           leaf_font_size = 12)\n",
    "plt.title('Иерархическая кластеризация: агломеративный алгоритм')\n",
    "plt.ylabel('Расстояние')\n",
    "plt.xlabel('Номера объектов')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Качество кластеризации\n",
    "\n",
    "[Кофенетическая корреляция](https://ranalytics.github.io/data-mining/103-Clustering-Quality.html)\n",
    "\n",
    "Ресурсы по теме:\n",
    "1. Ким Д.О. Факторный, дискриминантный и кластерный анализ /  Д.О. Ким, Ч.У. Мьюллер, У.Р. Клекка и др. --- М.: Финансы и статистика, 1989. --- 215 с."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c, coph_dists = cophenet(mergings, pdist(df_to_fit))\n",
    "c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Оптимальная структура разбиения: метод локтя"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "last = mergings[-15:, 2] # в матрице связей берем последние 20 значений расстояний между кластерами \n",
    "last_rev = last[::-1] #переписываем в обратном порядке  \n",
    "idxs = np.arange(1, len(last) + 1,1) #генерируем список начальное значение 1, конечное --- число элементов массива, шаг 1\n",
    "plt.xlabel('Число кластеров')\n",
    "plt.ylabel('Расстояние')\n",
    "plt.title('Метод локтя')\n",
    "plt.plot(idxs, last_rev) #отображение графика \n",
    "\n",
    "#далее идет расчет вторых разностей  \n",
    "acceleration = np.diff(last, 2) #расчет вторых разностей \n",
    "acceleration_rev = acceleration[::-1] #переписываем в обратном порядке\n",
    "plt.plot(idxs[:-2] + 1, acceleration_rev)\n",
    "plt.show()\n",
    "k = acceleration_rev.argmax() + 2   \n",
    "print(\"clusters:\", k)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "На данном графике показана зависимость расстояния между кластерами от номера шага итерации, на котором два ближайших кластера объединяются в новый --- синия линия.Оранжевая линия показывает, как меняется ускорение --- быстрота изменения расстояния между объединяемыми кластерами. В данном случае оптимальным числом кластеров может считаться 2 или 7. Ориентируясь на поведение функции расстояния, примем в качестве оптимальное разбиения --- разбиение на 7 кластеров. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Некоторая кластериазация: метод `fcluster()` \n",
    "\n",
    "Для выделения некоторого разбиения объектов на кластеры воспользуемся функцией `fcluster()`, которая на основе построенной матрицы связей выделяет некоторое разбиение на кластеры, исходя из задаваемых пользователем критериев. В качестве критерия можно указать либо максимальное количество кластеров `criterion='maxclust'`, либо расстоние `criterion='distance'`.\n",
    "\n",
    "В первом случае мы указываем требуемое (желаемое) максимальное число кластеров, т.е. используем критерий `criterion='maxclust'`. На выходе имеем массив с указанием номера кластера, которому принадлежит соответствующий исходный объект"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label=fcluster(mergings, 7, criterion='maxclust')\n",
    "len(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Анализ результатов кластеризации\n",
    "\n",
    "Для анализа каждого из выделенных кластеров реализуем следующие действия:    \n",
    "1) добавим в исходный датафрейм новый столбец `Номер кластера`;    \n",
    "2) с использоанием механизма группировки датафрейма `groupby` выведем объекты кластеров"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_to_cluster.loc[:,'Номер кластера'] = label # добавление нового столбца с метками \n",
    "df_to_cluster.head(10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_to_cluster['Номер кластера'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_to_cluster.groupby('Номер кластера')\\\n",
    "  .agg(Размерность_кластера = ('Номер кластера', 'count'))\\\n",
    "  .reset_index()\\\n",
    "  .sort_values(by = 'Размерность_кластера', ascending=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering(n_clusters=7)\n",
    "model = model.fit(df_to_fit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(model.labels_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Неиерархическая кластеризация: алгоритм  $к$-средних\n",
    "\n",
    "Алгоритм можно схематически представить в виде следующих шагов:\n",
    "\n",
    "1. Инициализируем центры кластеров случайно (должно быть задано количество кластеров).\n",
    "2. Относим точки к соответствующим кластерам (с минимальным расстоянием до их центра).\n",
    "3. Производится пересчет центров кластеров по формуле центра масс всех точек принадлежащих кластеру.\n",
    "4. Пункты 2-3 повторяются до тех пор пока центры кластеров перестанут меняться (сильно).\n",
    "\n",
    "\n",
    "Модуль `scipy.cluster.vq` предоставляет следующие возможности по реализации метода `k-средних`.\n",
    "- whiten(X[, check_finite]) #проводит нормализацию признаков по стандартному отклонению каждого столбца. Каждый элемент столбца делится на стандартное отклонение по этому столбцу. \n",
    "- vq(X, code_book[, check_finite])\n",
    "- kmeans(X, k_or_guess[, iter, thresh, …]) #\n",
    "- kmeans2(X, k[, iter, thresh, minit, …]) \n",
    "\n",
    "С помощью этих методов кластеризацию можно реализовать двумя сценариями.     \n",
    "- 1 Сценарий    \n",
    "     1.1 Исходные данные, предствленные матрицей \"объект-свойство\" $X$ нормализуются методом `whiten(X)`. В результате имеем нормализованный массив исходных данных X_norm;    \n",
    "     1.2 Нормализованный массив исходных данных X_norm разделяется на заданное число кластеров `k` с использованием метода `kmeans(X_norm, k)`. В результате имеем массив центроидов и минимальное значение функционала качества кластеризации;     \n",
    "     1.3 Нормализованный массив данных X_norm распределяется по найденным центроидам. Для этого используется метод `vq()`.\n",
    "\n",
    "- 2 сценарий\n",
    "    \n",
    "Итак, начнем с того, что импортируем методы `whiten()`, `vq()`,  `kmeans()` и `kmeans2` из модуля `scipy.cluster.vq`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import vq, kmeans, whiten, kmeans2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "centroid, opt = kmeans(df_to_fit, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(centroid, '\\n', 'Минимальное значение целевой функции: ', opt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_claster, dist = vq(df_to_fit, centroid)\n",
    "print('Массив меток кластеров: ', label_claster)\n",
    "print('Массив расстояний от элементов до центроидов: ', dist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counts_elem_in_cluster = np.bincount(label_claster)\n",
    "counts_elem_in_cluster\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_to_cluster.loc[:,'Номер кластера по к-средним']=label_claster\n",
    "df_to_cluster.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "#init='kmeans++' -- Метод инициализации.\n",
    "#n init=10 -- Количество запусков алгоритма с разными центроидами. Победит наилучший результат."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km = KMeans(7, random_state = 42)\n",
    "clusters = KMeans(7, random_state = 42).fit(df_to_fit)\n",
    "clusters.pr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "km.transform(df_to_fit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inertias = []\n",
    "sizes = range(2, 20)\n",
    "for k in sizes:\n",
    "  k2 = KMeans(random_state=42, n_clusters=k)\n",
    "  k2.fit(df_to_fit)\n",
    "  inertias.append(k2.inertia_)\n",
    "fig, ax= plt.subplots(figsize=(6, 4))\n",
    "pd.Series(inertias, index=sizes).plot()\n",
    "ax.set_xlabel(\"Количество кластеров\")\n",
    "ax.set_ylabel(\"Функционал\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Качество кластеризации\n",
    "\n",
    "- Коэффициент силуэта (silhouette coefficient) - это значение от -1 до 1. Чем выше оценка, тем лучше.\n",
    "- Индекс Калинского-Харабаза (Calinski-Harabasz Index) представляет\n",
    "собой отношение дисперсии между кластерами и внутри кластера. Чем выше оценка, тем лучше;\n",
    "- Индекс Дэвиса-Болдина (Davis-Bouldin Index) -- это среднее сходство между каждым кластером и ближайшим кластером. Оценки варьируются от 0 и выше. 0 указывает на лучшую кластеризацию."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "inertias = []\n",
    "sils = []\n",
    "chs = []\n",
    "dbs = []\n",
    "sizes = range(2, 12)\n",
    "for k in sizes:\n",
    "  k2 = KMeans(random_state=42, n_clusters=k)\n",
    "  k2.fit(df_to_fit)\n",
    "  inertias.append(k2.inertia_)\n",
    "  sils.append(metrics.silhouette_score(df_to_fit, k2.labels_))\n",
    "  chs.append(metrics.calinski_harabasz_score(df_to_fit, k2.labels_))\n",
    "  dbs.append(metrics.davies_bouldin_score(df_to_fit, k2.labels_))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "(pd.DataFrame({\n",
    "    \"inertia\": inertias,\n",
    "    \"silhouette\": sils,\n",
    "    \"calinski\": chs,\n",
    "    \"davis\": dbs,\n",
    "    \"k\": sizes})\n",
    ".set_index(\"k\").plot(ax=ax, subplots=True, layout=(2, 2))\n",
    ")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DBSCAN\n",
    "\n",
    "Это алгоритм, основанный на плотности — если дан набор объектов в некотором пространстве, алгоритм группирует вместе объекты, которые расположены близко и помечает как выбросы объекты, которые находятся в областях с малой плотностью (ближайшие соседи которых лежат далеко).\n",
    "\n",
    "Алгоритм имеет два основных гиперпараметра:\n",
    "1. `eps` &mdash; радиус рассматриваемой окрестности\n",
    "2. `min_samples` &mdash; число соседей в окрестности\n",
    "\n",
    "Для выполнения кластеризации DBSCAN точки делятся на основные точки, достижимые по плотности точки и выпадающие следующим образом:\n",
    "\n",
    "- Точка p является основной точкой, если по меньшей мере `min_samples` точек находятся на расстоянии, не превосходящем \n",
    "`eps` до неё. Говорят, что эти точки достижимы прямо из p.\n",
    "\n",
    "-  Точка q прямо достижима из p, если точка q находится на расстоянии, не большем \n",
    "ϵ , от точки p и p должна быть основной точкой.\n",
    "Точка A q достижима из p, если имеется путь \n",
    "$p_1,…,p_n$ где $p_1=p$ и $p_n=q$ , а каждая точка $p_{i+1}$ достижима прямо из $p_i$ (все точки на пути должны быть основными, за исключением $q$).\n",
    "\n",
    "Все точки, не достижимые из основных точек, считаются выбросами.\n",
    "\n",
    "Теперь, если $p$ является основной точкой, то она формирует кластер вместе со всеми точками (основными или неосновными), достижимые из этой точки. Каждый кластер содержит по меньшей мере одну основную точку. Неосновные точки могут быть частью кластера, но они формируют его «край», поскольку не могут быть использованы для достижения других точек.\n",
    "\n",
    "\n",
    "Рассмотрим диаграму\n",
    "\n",
    "<p><a href=\"https://commons.wikimedia.org/wiki/File:DBSCAN-Illustration.svg#/media/Файл:DBSCAN-Illustration.svg\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/DBSCAN-Illustration.svg/1200px-DBSCAN-Illustration.svg.png\" alt=\"DBSCAN-Illustration.svg\" width=\"450\" height=\"450\"> </a><br>Автор: <a href=\"//commons.wikimedia.org/wiki/User:Chire\" title=\"User:Chire\">Chire</a> &mdash; <span class=\"int-own-work\" lang=\"ru\">собственная работа</span>, <a href=\"https://creativecommons.org/licenses/by-sa/3.0\" title=\"Creative Commons Attribution-Share Alike 3.0\">CC BY-SA 3.0</a>\n",
    "\n",
    "На этой диаграмме `min_samples`=4\n",
    "\n",
    "Точка $A$ и другие красные точки являются основными точками, поскольку область с радиусом \n",
    "`eps` , окружающая эти точки, содержит по меньшей мере 4 точки (включая саму точку). Поскольку все они достижимы друг из друга, точки образуют один кластер. Точки $B$ и $C$ основными не являются, но достижимы из $A$ (через другие основные точки), и также принадлежат кластеру. Точка $N$ является точкой шума, она не является ни основной точкой, ни доступной прямо."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "samples = 5\n",
    "eps = 0.2\n",
    "dbscan = DBSCAN(eps=eps, min_samples=samples)\n",
    "clusters = dbscan.fit(df_to_fit)       "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clusters.labels_[clusters.labels_ > -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_excel('med_set_clear_azot.xlsx') \n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Работа с категориальными переменными\n",
    "\n",
    "Некоторые алгоритмы машинного обучения не могут работать с категориальными переменными, значения которых являются не являются количественными.\n",
    "\n",
    "В этом случае применяются различные схема кодирования значений категориальных переменных:\n",
    "- присвоение значениям переменной в лексикографическом порядке целочисленных значений -- LabelEncoder;\n",
    "- дамми-кодирование -- `.get_dummies()`;\n",
    "\n",
    "- cоздание переменной, у которой каждое значение -- частота наблюдений в категории переменных (Frequency Encoding)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "l_e =  LabelEncoder()\n",
    "l_e.fit(df['пол'])\n",
    "df['пол_чис'] = l_e.transform(df['пол'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.get_dummies(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ad = df['пол'].value_counts()/len(df)\n",
    "print(df['пол'].map(ad))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Тема 7.4 Нейронная сеть"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### История развития искусственного интеллекта\n",
    "\n",
    "Ключевые даты и события:\n",
    "- 1956 г. дартмунтский семинар;\n",
    "- 1958 г. персептрон Розенблатта;\n",
    "- 1969 — Марвин Минский и Сеймур Пейперт опубликовали книгу «Персептроны»;\n",
    "- Две длительные «зимы» относят к периодам 1974—1980 годов и 1987—1993 годов;\n",
    "- 2005-2006 — группы Хинтона и Бенджи научились обучать глубокие нейронные сети.\n",
    "\n",
    "Важные тренды:\n",
    "- точность растет;\n",
    "- сложность растет;\n",
    "- объемы данных растут;\n",
    "- вычислительные мощности растут.\n",
    "\n",
    "Литература:\n",
    "- Хайкин С. Нейронные сети: полный курс. --- 2-е изд. --- М.: Вильямс, 2006. --- 1104 с.\n",
    "- Николенко С., Кадурин А., Архангельская Е. Глубокое обучение. — СПб.: Питер, 2018. — 480 с.\n",
    "- Шолле Ф. Глубокое обучение на Python. — СПб.: Питер, 2018. — 400 с.\n",
    "- Гудфеллоу Я., Бенджио И., Курвилль А. Глубокое обучение / пер. с анг. А. А. Слинкина. – 2-е изд., испр. – М.: ДМК Пресс, 2018. – 652 с.\n",
    "\n",
    "### Модель нейрона\n",
    "\n",
    "Нейрон представляет собой единицу обработки информации в нейронной сети. \n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=184W_sirUmQXq2Bj-Zj2otGMO7zU0a5zg' width=\"650\" height=\"400\" />\n",
    "<figcaption>Модель нейрона</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "В этой модели можно выделить три основных элемента:\n",
    "- **Набор синапсов или связей**, каждый из которых характеризуется своим весом. В частности, сигнал $x_j$ на входе синапса $j$, связанного с нейроном $k$, умножается на вес $w_{kj}$. Первый индекс веса относится к рассматриваемому нейрону, а второй --- ко входу. Вес искусственного нейрона может иметь как положительные, так и отрицательные значения.\n",
    "- **Сумматор** складывает входные сигналы, взвешенные относительно со- \n",
    "ответствующих синапсов нейрона. Эту операцию можно описать как линейную \n",
    "комбинацию.\n",
    "- **Функция активации** ограничивает амплитуду выходного сигнала нейрона. Эта функция также называется функцией сжатия. Обычно нормализованный диапазон амплитуд выхода нейрона лежит в интервале [0,1] или [-1,1]. \n",
    "\n",
    "В математическом представлении функционирование нейрона к можно описать \n",
    "следующей парой уравнений: \n",
    "$$\n",
    "u_k = \\sum\\limits_{j=1}^{m}w_{kj}x_j,\n",
    "y_k = \\varphi(u_k+b_k).\n",
    "$$\n",
    "Здесь $x_1, x_2, \\ldots, x_m$ -- входные сигналы; $w_{k1}, w_{k2}, \\ldots, w_{km}$ --синаптические веса нейрона $k$; $u_k$ -- линейная комбинация входных воздействий; $b_k$ -- порог; $\\varphi(\\cdot)$ -- функция активации; $y_k$ -- выходной сигнал нейрона. \n",
    " \n",
    "### Перцептрон Розенблатта\n",
    "\n",
    "Основной компонент нейронной сети – перцептрон.\n",
    "\n",
    "Перцептрон – это линейная модель, применяемая для бинарной классификации.\n",
    "\n",
    "В нейронных сетях перцептрон рассматривается как искусственный нейрон со\n",
    "ступенчатой функцией Хевисайда в качестве функции активации.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=183sc8eCs-HGXi6wvQcOy_-8HT_-xxUTH' width=\"650\" height=\"400\" />\n",
    "<figcaption>Однослойный перцептрон</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "### Многослойные нейронные сети\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=189JgWo9yuPhd6G-xI7oKb8g0rKAH8PWo' width=\"650\" height=\"400\" />\n",
    "<figcaption>Архитектура многослойной сети</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "В многослойной нейронной сети имеются:\n",
    "- один входной слой;\n",
    "- один или несколько полносвязных скрытых слоев;\n",
    "- один выходной слой.\n",
    "\n",
    "У всех нейронов одного слоя одна и та же функция активации (как правило).\n",
    "\n",
    "**Входной слой** -- через этот слой в сеть поступают входные данные (векторы).\n",
    "Количество нейронов во входном слое обычно совпадает с количеством входных\n",
    "признаков.\n",
    "\n",
    "**Скрытый слой**. В нейронной сети прямого распространения имеется один или\n",
    "несколько скрытых слоев. Благодаря скрытым слоям сеть способна моделировать нелинейные функции.\n",
    "\n",
    "**Выходной слой** -- прогноз модели от выходного слоя.\n",
    "\n",
    "**Связи между слоями** -- в полносвязной сети прямого распространения каждый нейрон предыдущего слоя связан со всеми нейронами следующего слоя. Веса\n",
    "связей изменяются по мере того, как алгоритм обратного распространения ищет\n",
    "оптимальное решение.\n",
    "\n",
    "### Функции активации\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=18H2O-Wx88LGQsQZv2ZC5wPAfLpxgCG1k' width=\"600\" height=\"400\" />\n",
    "<figcaption>Функции активации</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "Ресурсы:\n",
    "- Николенко С., Кадурин А., Архангельская Е. Глубокое обучение. — СПб.: Питер, 2018. — 480 с.\n",
    "- Гудфеллоу Я., Бенджио И., Курвилль А. Глубокое обучение / пер. с анг. А. А. Слинкина. – 2-е изд., испр. – М.: ДМК Пресс, 2018. – 652 с.\n",
    "\n",
    "### Архитектуры нейронных сетей\n",
    "Ресурсы: \n",
    "1. [Зоопарк нейронных сетей. Часть 1](https://habr.com/ru/company/wunderfund/blog/313696/) \n",
    "2. [Зоопарк архитектур нейронных сетей. Часть 2](https://habr.com/ru/company/wunderfund/blog/313906/)\n",
    "\n",
    "### Обучение нейронных сетей\n",
    "Пусть $X$ - множество входов нейронной сети, $Y$ -- соответствующие им истинные значения зависимой переменной, $W$ -- матрица весов; $\\varphi()$ -- функция активации. Пусть также $\\widehat{Y} = \\varphi(X,W)$ -- прогнозные значения, найденные с помощью нейронной сети. Тогда функцию вида\n",
    "$$\n",
    "L = \\Lambda(\\widehat{Y}, Y) \n",
    "$$\n",
    "будем называть функцией потерь.\n",
    "\n",
    "\n",
    "Обучение сети сводится к решению оптимизационной задачи\n",
    "$$\n",
    "L(X,W) \\to \\min\\limits_{W}\n",
    "$$\n",
    "\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=18Q964KHy_9y0866w2QUsLBq4PF7DvTbh' width=\"700\" height=\"600\" />\n",
    "<figcaption>Алгоритм обратного распространения ошибки</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "### Глубокое обучение\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=18MjkBIwuzhMHkC0tMIY0-I0e3qyetS4j' width=\"700\" height=\"600\" />\n",
    "<figcaption>Идея глубокого обучения</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "Глубокое обучение -- это наука о моделях, в которых уровень композиции обученных функций или обученных концепций выше, чем в традиционном машинном обучении.\n",
    "\n",
    "Значимые успехи моделей глубокого обучения:\n",
    "- классификация изображений на уровне человека;\n",
    "- распознавание речи на уровне человека;\n",
    "- распознавание рукописного текста на уровне человека;\n",
    "- улучшение качества машинного перевода с одного языка на другой;\n",
    "- улучшение качества машинного чтения текста вслух;\n",
    "- появление цифровых помощников, таких как Google Now и Amazon Alexa;\n",
    "- управление автомобилем на уровне человека;\n",
    "- повышение точности целевой рекламы;\n",
    "- повышение релевантности поиска в интернете;\n",
    "- появление возможности отвечать на вопросы, заданные вслух;\n",
    "- игра в Go сильнее человека.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ad = df['пол'].value_counts()/len(df)\n",
    "print(df['пол'].map(ad))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4FLQDqyApoR5",
    "outputId": "8c4077c0-d08b-42b8-ae00-76c520d2f221"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0     0.163265\n",
      "1     0.836735\n",
      "2     0.836735\n",
      "3     0.836735\n",
      "4     0.163265\n",
      "5     0.836735\n",
      "6     0.163265\n",
      "7     0.836735\n",
      "8     0.836735\n",
      "9     0.836735\n",
      "10    0.163265\n",
      "11    0.836735\n",
      "12    0.836735\n",
      "13    0.836735\n",
      "14    0.163265\n",
      "15    0.163265\n",
      "16    0.836735\n",
      "17    0.836735\n",
      "18    0.836735\n",
      "19    0.836735\n",
      "20    0.163265\n",
      "21    0.163265\n",
      "22    0.836735\n",
      "23    0.836735\n",
      "24    0.836735\n",
      "25    0.836735\n",
      "26    0.836735\n",
      "27    0.836735\n",
      "28    0.836735\n",
      "29    0.836735\n",
      "30    0.836735\n",
      "31    0.836735\n",
      "32    0.836735\n",
      "33    0.836735\n",
      "34    0.836735\n",
      "35    0.836735\n",
      "36    0.836735\n",
      "37    0.836735\n",
      "38    0.836735\n",
      "39    0.836735\n",
      "40    0.836735\n",
      "41    0.836735\n",
      "42    0.836735\n",
      "43    0.836735\n",
      "44    0.836735\n",
      "45    0.836735\n",
      "46    0.836735\n",
      "47    0.836735\n",
      "48    0.836735\n",
      "Name: пол, dtype: float64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Тема 7.4 Нейронная сеть"
   ],
   "metadata": {
    "id": "QWbuGVuHA0cG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### История развития искусственного интеллекта\n",
    "\n",
    "Ключевые даты и события:\n",
    "- 1956 г. дартмунтский семинар;\n",
    "- 1958 г. персептрон Розенблатта;\n",
    "- 1969 — Марвин Минский и Сеймур Пейперт опубликовали книгу «Персептроны»;\n",
    "- Две длительные «зимы» относят к периодам 1974—1980 годов и 1987—1993 годов;\n",
    "- 2005-2006 — группы Хинтона и Бенджи научились обучать глубокие нейронные сети.\n",
    "\n",
    "Важные тренды:\n",
    "- точность растет;\n",
    "- сложность растет;\n",
    "- объемы данных растут;\n",
    "- вычислительные мощности растут.\n",
    "\n",
    "Литература:\n",
    "- Хайкин С. Нейронные сети: полный курс. --- 2-е изд. --- М.: Вильямс, 2006. --- 1104 с.\n",
    "- Николенко С., Кадурин А., Архангельская Е. Глубокое обучение. — СПб.: Питер, 2018. — 480 с.\n",
    "- Шолле Ф. Глубокое обучение на Python. — СПб.: Питер, 2018. — 400 с.\n",
    "- Гудфеллоу Я., Бенджио И., Курвилль А. Глубокое обучение / пер. с анг. А. А. Слинкина. – 2-е изд., испр. – М.: ДМК Пресс, 2018. – 652 с.\n",
    "\n",
    "### Модель нейрона\n",
    "\n",
    "Нейрон представляет собой единицу обработки информации в нейронной сети. \n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=184W_sirUmQXq2Bj-Zj2otGMO7zU0a5zg' width=\"650\" height=\"400\" />\n",
    "<figcaption>Модель нейрона</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "В этой модели можно выделить три основных элемента:\n",
    "- **Набор синапсов или связей**, каждый из которых характеризуется своим весом. В частности, сигнал $x_j$ на входе синапса $j$, связанного с нейроном $k$, умножается на вес $w_{kj}$. Первый индекс веса относится к рассматриваемому нейрону, а второй --- ко входу. Вес искусственного нейрона может иметь как положительные, так и отрицательные значения.\n",
    "- **Сумматор** складывает входные сигналы, взвешенные относительно со- \n",
    "ответствующих синапсов нейрона. Эту операцию можно описать как линейную \n",
    "комбинацию.\n",
    "- **Функция активации** ограничивает амплитуду выходного сигнала нейрона. Эта функция также называется функцией сжатия. Обычно нормализованный диапазон амплитуд выхода нейрона лежит в интервале [0,1] или [-1,1]. \n",
    "\n",
    "В математическом представлении функционирование нейрона к можно описать \n",
    "следующей парой уравнений: \n",
    "$$\n",
    "u_k = \\sum\\limits_{j=1}^{m}w_{kj}x_j,\n",
    "y_k = \\varphi(u_k+b_k).\n",
    "$$\n",
    "Здесь $x_1, x_2, \\ldots, x_m$ -- входные сигналы; $w_{k1}, w_{k2}, \\ldots, w_{km}$ --синаптические веса нейрона $k$; $u_k$ -- линейная комбинация входных воздействий; $b_k$ -- порог; $\\varphi(\\cdot)$ -- функция активации; $y_k$ -- выходной сигнал нейрона. \n",
    " \n",
    "### Перцептрон Розенблатта\n",
    "\n",
    "Основной компонент нейронной сети – перцептрон.\n",
    "\n",
    "Перцептрон – это линейная модель, применяемая для бинарной классификации.\n",
    "\n",
    "В нейронных сетях перцептрон рассматривается как искусственный нейрон со\n",
    "ступенчатой функцией Хевисайда в качестве функции активации.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=183sc8eCs-HGXi6wvQcOy_-8HT_-xxUTH' width=\"650\" height=\"400\" />\n",
    "<figcaption>Однослойный перцептрон</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "### Многослойные нейронные сети\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=189JgWo9yuPhd6G-xI7oKb8g0rKAH8PWo' width=\"650\" height=\"400\" />\n",
    "<figcaption>Архитектура многослойной сети</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "В многослойной нейронной сети имеются:\n",
    "- один входной слой;\n",
    "- один или несколько полносвязных скрытых слоев;\n",
    "- один выходной слой.\n",
    "\n",
    "У всех нейронов одного слоя одна и та же функция активации (как правило).\n",
    "\n",
    "**Входной слой** -- через этот слой в сеть поступают входные данные (векторы).\n",
    "Количество нейронов во входном слое обычно совпадает с количеством входных\n",
    "признаков.\n",
    "\n",
    "**Скрытый слой**. В нейронной сети прямого распространения имеется один или\n",
    "несколько скрытых слоев. Благодаря скрытым слоям сеть способна моделировать нелинейные функции.\n",
    "\n",
    "**Выходной слой** -- прогноз модели от выходного слоя.\n",
    "\n",
    "**Связи между слоями** -- в полносвязной сети прямого распространения каждый нейрон предыдущего слоя связан со всеми нейронами следующего слоя. Веса\n",
    "связей изменяются по мере того, как алгоритм обратного распространения ищет\n",
    "оптимальное решение.\n",
    "\n",
    "### Функции активации\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=18H2O-Wx88LGQsQZv2ZC5wPAfLpxgCG1k' width=\"600\" height=\"400\" />\n",
    "<figcaption>Функции активации</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "Ресурсы:\n",
    "- Николенко С., Кадурин А., Архангельская Е. Глубокое обучение. — СПб.: Питер, 2018. — 480 с.\n",
    "- Гудфеллоу Я., Бенджио И., Курвилль А. Глубокое обучение / пер. с анг. А. А. Слинкина. – 2-е изд., испр. – М.: ДМК Пресс, 2018. – 652 с.\n",
    "\n",
    "### Архитектуры нейронных сетей\n",
    "Ресурсы: \n",
    "1. [Зоопарк нейронных сетей. Часть 1](https://habr.com/ru/company/wunderfund/blog/313696/) \n",
    "2. [Зоопарк архитектур нейронных сетей. Часть 2](https://habr.com/ru/company/wunderfund/blog/313906/)\n",
    "\n",
    "### Обучение нейронных сетей\n",
    "Пусть $X$ - множество входов нейронной сети, $Y$ -- соответствующие им истинные значения зависимой переменной, $W$ -- матрица весов; $\\varphi()$ -- функция активации. Пусть также $\\widehat{Y} = \\varphi(X,W)$ -- прогнозные значения, найденные с помощью нейронной сети. Тогда функцию вида\n",
    "$$\n",
    "L = \\Lambda(\\widehat{Y}, Y) \n",
    "$$\n",
    "будем называть функцией потерь.\n",
    "\n",
    "\n",
    "Обучение сети сводится к решению оптимизационной задачи\n",
    "$$\n",
    "L(X,W) \\to \\min\\limits_{W}\n",
    "$$\n",
    "\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=18Q964KHy_9y0866w2QUsLBq4PF7DvTbh' width=\"700\" height=\"600\" />\n",
    "<figcaption>Алгоритм обратного распространения ошибки</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "### Глубокое обучение\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?export=view&id=18MjkBIwuzhMHkC0tMIY0-I0e3qyetS4j' width=\"700\" height=\"600\" />\n",
    "<figcaption>Идея глубокого обучения</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "Глубокое обучение -- это наука о моделях, в которых уровень композиции обученных функций или обученных концепций выше, чем в традиционном машинном обучении.\n",
    "\n",
    "Значимые успехи моделей глубокого обучения:\n",
    "- классификация изображений на уровне человека;\n",
    "- распознавание речи на уровне человека;\n",
    "- распознавание рукописного текста на уровне человека;\n",
    "- улучшение качества машинного перевода с одного языка на другой;\n",
    "- улучшение качества машинного чтения текста вслух;\n",
    "- появление цифровых помощников, таких как Google Now и Amazon Alexa;\n",
    "- управление автомобилем на уровне человека;\n",
    "- повышение точности целевой рекламы;\n",
    "- повышение релевантности поиска в интернете;\n",
    "- появление возможности отвечать на вопросы, заданные вслух;\n",
    "- игра в Go сильнее человека.\n"
   ],
   "metadata": {
    "id": "Ztz6Q3GGMv8r"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "0fTfRx_ItJXE"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}